{"cells": [{"cell_type": "markdown", "id": "8563d04d", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["# Tutorial 2\n", "## May 4, 2023"]}, {"cell_type": "markdown", "id": "0405f658", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["# Convolution and cross-correlation"]}, {"cell_type": "markdown", "id": "40a47af7", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["In the previous tutorial, you have looked at images. Now, we're going to look at the effect of applying some filters to our image. First, load the image that you used last week.\n", "The images used in the different tutorials are available [here](https://surfdrive.surf.nl/files/index.php/s/hHQNmEOYd054V6f).\n", "For this tutorial you only need to download the folder \"Tutorial 1\"."]}, {"cell_type": "code", "execution_count": null, "id": "70460c12", "metadata": {}, "outputs": [], "source": ["data_path = r'C:\\Users\\WolterinkJM\\Downloads'"]}, {"cell_type": "code", "execution_count": null, "id": "4fa7ed42", "metadata": {}, "outputs": [], "source": ["import os\n", "import SimpleITK as sitk\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "image_file = os.path.join(data_path, r'TEV1P1CTI.mhd')\n", "\n", "if not os.path.exists(image_file):\n", "    print(f'The image could not be found. '\n", "          f'Please check that the file TEV1P1CTI.mhd can be found in {data_path}')\n", "else:\n", "    image = sitk.ReadImage(image_file)\n", "    image_array = sitk.GetArrayFromImage(image)\n", "    image_array = np.swapaxes(image_array, 0, 2)"]}, {"cell_type": "markdown", "id": "b86139ca", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["To make life simple, we just consider a 2D image, and we downsample the image by a factor 4 so the effect of filters is more clear. There are many ways to do this, here we use the [SciPy](https://docs.scipy.org/doc/scipy/index.html) package."]}, {"cell_type": "code", "execution_count": null, "id": "4d673710", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["import scipy.ndimage as scnd\n", "from IPython.display import display, clear_output\n", "\n", "# Only consider one image slice\n", "image_slice = image_array[:, :, 20].squeeze().transpose()\n", "\n", "# Use Scipy to downsample the image by a factor 4\n", "image_slice = scnd.zoom(image_slice, 0.25)\n", "\n", "plt.title(\"Downsampled slice\")\n", "plt.imshow(image_slice, cmap=\"gray\")\n", "plt.show()"]}, {"cell_type": "markdown", "id": "78252a33", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["### Correlation and convolution"]}, {"cell_type": "markdown", "id": "b2fc0631", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["First, we're going to visualize what the difference between convolution and cross-correlation is. You (hopefully) remember from the lecture that convolution of an image $h$ with a kernel $g$ is $f(i,j) = \\sum_m\\sum_n h(i-m, j-n)g(m,n)$ whereas cross-correlation is defined as $f(i,j) = \\sum_m\\sum_n h(i+m, j+n)g(m,n)$. First define a *filter* or *kernel*:"]}, {"cell_type": "code", "execution_count": null, "id": "624571c8", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["g = np.array([[0, 0, 0],\n", "              [0, 0, 1],\n", "              [0, 0, 0]])"]}, {"cell_type": "markdown", "id": "43f0973e", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "  \u2328\ufe0f <b>Exercise</b>: \u2753 Without running the code below, try to figure out what the kernel will do when applied to an image in either convolution or cross-correlation.\n", "</div>"]}, {"cell_type": "markdown", "id": "f580951d", "metadata": {"tags": ["student"]}, "source": ["Your answer goes here."]}, {"cell_type": "markdown", "id": "db5fe862", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["Let's first apply the kernel with cross-correlation <code>scnd.correlate</code> and see what it does. We apply the kernel a couple of times so you see what's happening."]}, {"cell_type": "code", "execution_count": null, "id": "ca33bb42", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["filtered_image = image_slice\n", "\n", "fig = plt.figure()\n", "ax = fig.add_subplot(1, 1, 1) \n", "\n", "for level in range(20): # The kernel is applied 20 times\n", "    filtered_image = scnd.correlate(filtered_image, g, mode='constant', cval=0)\n", "    ax.imshow(filtered_image, cmap='gray', clim=[-300, 450])\n", "    ax.set_title('Applied {} times'.format(level))\n", "    display(fig)\n", "    \n", "    clear_output(wait = True)\n", "    plt.pause(0.1)"]}, {"cell_type": "markdown", "id": "9a49f957", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "  \u2328\ufe0f <b>Exercise</b>: \u2753 What happens when you use <code>scnd.correlate</code> instead of <code>scnd.convolve</code>. Try below. Can you explain this behavior?\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "id": "65d9554f", "metadata": {"tags": ["student"]}, "outputs": [], "source": ["## FILL IN \u2328\ufe0f"]}, {"cell_type": "markdown", "id": "56665c01", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["Of course we're not limited to shifting images left or right, we can also define kernels to, e.g., smooth or sharpen or image. A well-known smoothing kernel is the Gaussian kernel, which resembles a 2D normal distribution. Try to implement the kernel below and apply it once to your image.<br>\n", "<img src=\"https://4.bp.blogspot.com/-v4dH8qhFnEE/WqHaTPel8RI/AAAAAAAAI8g/AxIVu5i7mHU5UDcu6BkJQJj_UO11sMomwCLcBGAs/s200/3x3%2BGaussian%2BKernel.png\" />\n"]}, {"cell_type": "code", "execution_count": null, "id": "7dd82846", "metadata": {"tags": ["student"]}, "outputs": [], "source": ["## FILL IN \u2328\ufe0f"]}, {"cell_type": "markdown", "id": "38fac8f8", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "  \u2328\ufe0f <b>Exercise</b>: \u2753 What happens if you use correlate, and what happens if you use convolve?\n", "</div>"]}, {"cell_type": "markdown", "id": "b879a7e3", "metadata": {"tags": ["student"]}, "source": ["Your answer goes here"]}, {"cell_type": "markdown", "id": "cd5592e5", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["## PyTorch\n", "![PyTorch](https://upload.wikimedia.org/wikipedia/commons/9/96/Pytorch_logo.png?20211003060202)<br>\n", "[PyTorch](https://pytorch.org/) is (along with TensorFlow) one of the two most commonly used Python libraries for deep learning and linear algebra on GPUs. Before we jump into any real deep learning, there is a couple of things that you should know. Like NumPy, PyTorch operates on matrices. However, while NumPy calls these *arrays*, PyTorch calls them *tensors*. We can easily go back and forth between NumPy arrays and PyTorch tensors. See for yourself:"]}, {"cell_type": "code", "execution_count": null, "id": "b933a9dd", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["import torch\n", "\n", "# Start with a NumPy array\n", "a = np.array([1, 2, 3])\n", "print(type(a))\n", "print(a)\n", "\n", "# Convert to PyTorch tensor\n", "a_t = torch.from_numpy(a)\n", "print(type(a_t))\n", "print(a_t)\n", "\n", "# Convert back to NumPy array\n", "a = a_t.numpy()\n", "print(type(a))\n", "print(a)"]}, {"cell_type": "markdown", "id": "c980b276", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["PyTorch is supported on CPUs, GPUs, TPUs and (newer) MacBooks. You can set your device as follows."]}, {"cell_type": "code", "execution_count": null, "id": "c59fddfe", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["if torch.cuda.is_available():\n", "    # CUDA\n", "    gpu = torch.device('cuda:0')\n", "else:\n", "    # MacBook with >M1 chip\n", "    gpu = torch.device('mps')\n", "\n", "try:\n", "    a_t = a_t.to(device=gpu)\n", "except Exception:\n", "    print(\"No GPU was found on your machine.\"\n", "          \"Use colab or JupyterLab to access a GPU.\")"]}, {"cell_type": "markdown", "id": "bb993fbf", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["Note that the tensor is now on the GPU, so we cannot add a tensor that's on the CPU to it. For example, in the following line we initialize a new tensor on the CPU and try to add it but we get an error."]}, {"cell_type": "code", "execution_count": null, "id": "c8b8c05b", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["summed = a_t + torch.Tensor([4, 5, 6])"]}, {"cell_type": "markdown", "id": "ff549e02", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "  \u2328\ufe0f <b>Exercise</b>: \u2753 Try to fix this bug so you can add the tensors on the GPU.\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "id": "a87a9708", "metadata": {"tags": ["student"]}, "outputs": [], "source": ["## FILL IN \u2328\ufe0f"]}, {"cell_type": "markdown", "id": "c33a46e2", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["However, best practice is to initialize your tensors and objects directly on the GPU. For example, the code below will generate a random $1000\\times 1000$ matrix on the GPU. "]}, {"cell_type": "code", "execution_count": null, "id": "146aa930", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["rn = torch.randn(1000, 1000, device=gpu)\n", "print(rn)"]}, {"cell_type": "markdown", "id": "a5478bf4", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["Now let's perform *convolution* in PyTorch! For this, we use the [<code>conv2d</code>](https://pytorch.org/docs/stable/generated/torch.nn.functional.conv2d.html) function. The code below is not very different from what we have done before, but now everything happens in PyTorch instead of NumPy."]}, {"cell_type": "code", "execution_count": null, "id": "86cf5f1e", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["import torch.nn.functional as F\n", "\n", "image_slice_t = torch.from_numpy(image_slice).float()\n", "\n", "g_t = torch.tensor([[0, 0, 0],\n", "                    [0, 0, 1],\n", "                    [0, 0, 0]]).float()\n", "\n", "# We reshape the image because the conv2d function expects [batch_size, channels, width, height] inputs and kernels. You'll see \n", "# later what we mean with batch_size and channels.\n", "filtered_image_t = F.conv2d(image_slice_t.reshape((1, 1, 128, 128)), g_t.reshape((1, 1, 3, 3)), padding='same').squeeze()\n", "\n", "fig = plt.figure()\n", "ax = fig.add_subplot(1, 1, 1) \n", "for level in range(1, 20):\n", "    filtered_image_t = F.conv2d(filtered_image_t.reshape((1, 1, 128, 128)), g_t.reshape((1, 1, 3, 3)), padding='same').squeeze()\n", "    ax.imshow(filtered_image_t.numpy(), cmap='gray', clim=[-300, 450])\n", "    ax.set_title('Applied {} times'.format(level))\n", "    display(fig)\n", "    \n", "    clear_output(wait = True)\n", "    plt.pause(0.1)"]}, {"cell_type": "markdown", "id": "1fcf7626", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "  \u2328\ufe0f <b>Exercise</b>: \u2753 And, what do you see? A convolution or a cross-correlation? (Why) is this surprising?\n", "</div>"]}, {"cell_type": "markdown", "id": "3fcf084f", "metadata": {"tags": ["student"]}, "source": ["Answer:"]}, {"cell_type": "markdown", "id": "9f03a59e", "metadata": {}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "  \u2328\ufe0f <b>Exercise</b>: \u2753 All kernels that we have used so far are $3\\times 3$ elements, but this is an arbitrary choice. Can you implement a kernel that lets the image make a <a href=\"https://en.wikipedia.org/wiki/Knight_(chess)\">horse jump</a> to the top right? Implement the kernel and apply with PyTorch.\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "id": "221e21fc", "metadata": {"tags": ["student"]}, "outputs": [], "source": ["## FILL IN \u2328\ufe0f"]}, {"cell_type": "markdown", "id": "d19502d4", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["# Learning parameters from synthetic data\n", "In this part of the tutorial, we will define a very simple optimization problem and how to tackle it with PyTorch.\n", "In the next part of the tutorial, we will use MONAI, which is a PyTorch extension for medical images.\n", "\n", "Like in the lecture, we will solve a linear regression problem with one independent input variable $x$ and one\n", "dependent output variable $y$. The output variable is a function of the input, i.e.\n", "\n", "$$y = wx + b$$\n", "\n", "The measurements contain some noise, and thus, we're looking at an optimization problem\n", "\n", "$$\\underset{w,b}{arg\\,min}\\frac{1}{m}\\sum_{i}^m (wx_i+b-y_i)^2$$\n", "\n", "In this example, we will perform basic linear regression using PyTorch.\n", "First, we will generate our 'dataset', consisting of $x$ and $y$ values sampled along a line (with some added noise).\n", "We here use PyTorch (torch) functions to initialize our data."]}, {"cell_type": "code", "execution_count": null, "id": "2ee6b0a6", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["# Generation of a data set including N samples\n", "N = 50\n", "x = torch.linspace(0, 4, N, device=gpu)\n", "b = 4\n", "w = 2\n", "noise = torch.normal(torch.zeros(N)).to(gpu)\n", "y = (w * x + b + noise).float()\n", "\n", "# Plot the synthetic data set\n", "plt.figure()\n", "plt.title(\"Synthetic data\")\n", "plt.scatter(x.cpu(), y.cpu(), color='r') # We use this code to map the data back to the CPU\n", "plt.xlim(-1, 5)\n", "plt.xlabel('$x$')\n", "plt.ylim(0, 15)\n", "plt.ylabel('$y$')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "15194422", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["Here we want to learn a linear regression, so we don't need a deep neural network with non-linear activations,\n", "but only one fully-connected layer. In PyTorch, this is called a\n", "[Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) layer,\n", "as it learns a linear relation between inputs and outputs.\n", "Take a look at the documentation to see which arguments this layer has.\n", "\n", "The arguments we define are the following:\n", "1. The **number of input features**, which is in this case 1, i.e., x.\n", "2. The **number of output features**, which is in this case also 1, i.e., y.\n", "3. [Optional] We choose to define whether or not the layer has a **bias term**. By default, this is set to True.\n", "4. [Optional] We define here which **device** is used to instantiate the layer. In our case, we use a GPU."]}, {"cell_type": "code", "execution_count": null, "id": "1bae9b80", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["model = torch.nn.Linear(in_features=1, out_features=1, bias=True, device=gpu)"]}, {"cell_type": "markdown", "id": "8fdaa167", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["Like any neural network in PyTorch, training this network requires an loss function. Because this is a regression problem, we use a mean squared error loss, or [<code>MSELoss</code>](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html) in PyTorch, with default settings."]}, {"cell_type": "code", "execution_count": null, "id": "89bdf494", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["loss_func = torch.nn.MSELoss()"]}, {"cell_type": "markdown", "id": "81c67b04", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["We now define a simple training procedure to fit a model to a dataset. There are a few *very* important steps in this piece of code. \n", "\n", "- First, we create the optimizer, which is an essential part of training the model. In this case, we use an [SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html) optimizer, which is the gradient descent optimizer that you saw in the lecture. The optimizer keeps track of the parameters of the model and is initialized with a learning rate.\n", "- Second, we loop over a number of iterations and in each iteration we perform the following steps\n", "    - <code>optimizer.zero_grad() </code> resets all gradients of the model parameters. If we wouldn't do this, gradients would be added up over iterations.\n", "    - <code>output = model(x.unsqueeze(1))</code> applies the network to the input sample.\n", "    - <code>loss = loss_function(output, y.unsqueeze(1))</code> computes the MSE loss between the output of the network and the target, i.e., $y$.\n", "    - <code>loss.backward()</code> backpropagates the prediction loss to all parameters.\n", "    - <code>optimizer.step()</code> applied gradient descent the parameters by the gradients collected in the backward pass.\n", "    \n", "These few lines are at the core of anything you'll do in PyTorch. Note that this is only a very short description of the process, if you want to know more, take a look at [this tutorial](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html)."]}, {"cell_type": "code", "execution_count": null, "id": "eec49c54", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["import tqdm\n", "\n", "def train(model, iterations, lr, loss_function, x, y):\n", "    model.reset_parameters()\n", "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n", "    train_loss = []\n", "    for iteration in tqdm.tqdm(range(iterations)):\n", "        optimizer.zero_grad()\n", "        output = model(x.unsqueeze(1))\n", "        loss = loss_function(output, y.unsqueeze(1))\n", "        train_loss.append(loss.item())\n", "        loss.backward()\n", "        optimizer.step()\n", "    return model, train_loss"]}, {"cell_type": "markdown", "id": "d9c3f52b", "metadata": {}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "  \u2328\ufe0f <b>Exercise</b>: \u2753 Does this piece of code use batch gradient descent, mini-batch gradient descent or stochastic gradient descent?\n", "</div>"]}, {"cell_type": "markdown", "id": "3a37161b", "metadata": {"lines_to_next_cell": 2, "tags": ["student"]}, "source": ["Answer:"]}, {"cell_type": "markdown", "id": "7b157376", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "  \u2328\ufe0f <b>Exercise</b>: \u2753 Train the model for 1000 iterations with a learning rate of 0.001 and visualize the loss over time. What happens to the loss curve if you increase or decrease the learning rate (i.e. in steps of factor 10)?\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "id": "70b9bc46", "metadata": {"pycharm": {"name": "#%%\n"}, "tags": ["student"]}, "outputs": [], "source": ["# FILL IN THE RIGHT ARGUMENTS \u2328\ufe0f\n", "model_trained, loss = train(model=model, iterations=XXXXX, lr=XXXX, loss_function=loss_func, x=x, y=y)\n", "\n", "plt.plot(loss)\n", "plt.xlabel('Iterations')\n", "plt.ylabel('MSE loss')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "5e7d3de0", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["with torch.no_grad():\n", "    output = model_trained(x.unsqueeze(1))\n", "plt.plot(x.cpu(), output.cpu(), label='prediction')\n", "plt.scatter(x.cpu(), y.cpu(), color='r', label='training data')\n", "plt.xlim(-1, 5)\n", "plt.xlabel('$x$')\n", "plt.ylim(0, 15)\n", "plt.ylabel('$y$')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "id": "93741780", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "  \u2328\ufe0f <b>Exercise</b>: \u2753 Remember how when we defined <code>model</code> we set <code>bias</code> to <code>True</code>? Try to run the code again but without bias. What do you notice? The following line counts the number of trainable parameters in a model. What's the difference between the model with and without bias?\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "id": "cc1b6427", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["# This block counts the number of parameters in the model.\n", "sum(p.numel() for p in model.parameters() if p.requires_grad)"]}, {"cell_type": "code", "execution_count": null, "id": "3d1de10d", "metadata": {"tags": ["student"]}, "outputs": [], "source": ["# RETRAIN A MODEL WITHOUT BIAS \u2328\ufe0f"]}, {"cell_type": "markdown", "id": "12551d08", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["# Part 4: A convolutional neural network\n", "\n", "![MONAI](https://monai.io/assets/img/MONAI-logo_color_full.png)\n", "\n", "Medical Open Network for Artificial Intelligence ([MONAI](https://monai.io/)) is the library we will use in this course for deep learning on medical images. MONAI is built on the same concepts as PyTorch and its classes in many cases inherit from PyTorch classes. However, MONAI has specific functions and models that make it appropriate for medical images. The 'raw' loaded medical images are often not directly suited for training a neural network; they need to be processed before being used. MONAI offers a streamlined framework for transforming the data and feeding it into the network. In practice, you will use a combination of the two. A typical workflow in both PyTorch and MONAI is as follows:\n", "1. Define a dataset\n", "2. Define transforms on the dataset to make it suitable for the network\n", "3. Build a dataloader\n", "4. Build the network / define the optimizer, loss function and hyperparameters\n", "5. Start training procedure \n", "\n", "In this tutorial, we build a classification network for tumor classification, using datasets from [MedMNIST](https://medmnist.com/). This is a collection of datasets with binary (yes or no) or multiclass labels in 2D or 3D. Each sample in these datasets is a $28\\times 28$ pixel (2D) or $28\\times 28\\times 28$ voxel (3D) image. To be able to use MONAI and this repository, we install the corresponding Python package using the following cell."]}, {"cell_type": "code", "execution_count": null, "id": "727a506d", "metadata": {}, "outputs": [], "source": ["!pip install monai\n", "!pip install medmnist"]}, {"cell_type": "markdown", "id": "f9af203d", "metadata": {}, "source": ["After you've installed the `medmnist` package, import it and download the `train` segment of the pneumonia dataset. This is a binary task where patients either have pneumonia or don't. Note that there is also a `validate` and `test` segment that we will download later."]}, {"cell_type": "code", "execution_count": null, "id": "c169817f", "metadata": {}, "outputs": [], "source": ["import medmnist\n", "dataset = medmnist.PneumoniaMNIST(split=\"train\", download=True)"]}, {"cell_type": "markdown", "id": "8e8f84b3", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["## Datasets\n", "The first step in the procedure consists of building a dataset that contains the images and labels. A dataset is an object, that we build using the PyTorch <code>Dataset</code> class template. Remember the <code> Car </code> class from last tutorial, with class-specific functions accelerate and brake? Here, we build a custom dataset object, where we need to define three functions in the dataset:\n", "- `__init__`: runs when constructing the object, place where you can construct paths to the data and save them in an array, or load the images in an array.\n", "- `__len__`: returns length of the dataset, i.e. number of samples.\n", "- `__getitem__`: returns a sample from the dataset. This function takes an index as input, and returns the corresponding sample in the dataset. In our case, this would be two objects: an image and its corresponding label. This function returns a dictionary containing image and label. The advantage of using a dictionary is that you can keep track of transforms on the data later on in the pipeline.\n", "\n", "The `MedMNISTData` class below inherits from the MONAI `Dataset` class, which in turn inherits from the PyTorch `Dataset` class."]}, {"cell_type": "code", "execution_count": null, "id": "a26cf9ff", "metadata": {}, "outputs": [], "source": ["import os\n", "import monai\n", "\n", "class MedMNISTData(monai.data.Dataset):\n", "    \n", "    def __init__(self, datafile, transform=None):\n", "        self.data = datafile\n", "        self.transform = transform\n", "        \n", "        \n", "    def __getitem__(self, index):\n", "        # Make getitem return a dictionary with keys ['img', 'label'] for the image and label respectively\n", "        image = self.data[index][0]\n", "        if self.transform:\n", "            image = self.transform(image)\n", "        return {'img': image, 'label': self.data[index][1]}\n", "    \n", "    def __len__(self):\n", "        return len(self.data)"]}, {"cell_type": "markdown", "id": "f4e9034b", "metadata": {}, "source": ["Note that in `__getitem__` we apply a transform to each image that is selected. Such a transform is simply a function or a composition of functions that can be applied to a sample to transform it into another sample. This typically includes things like intensity normalization, cropping, resampling, etc. and are essential to most deep learning pipelines in medical imaging. Here we compose two simple transforms:\n", "- The `ToTensor` transform converts an image into a PyTorch `Tensor` type\n", "- The `Normalize` transform normalizes the intensities of an image to mean=0.5 and std=0.5 (in this case)\n", "\n", "MONAI and other Python libraries like [TorchIO](https://torchio.readthedocs.io/) contain many convenient functions to transform your images."]}, {"cell_type": "code", "execution_count": null, "id": "5a11f18b", "metadata": {}, "outputs": [], "source": ["import torchvision.transforms as transforms\n", "\n", "data_transform = transforms.Compose([\n", "    transforms.ToTensor(),\n", "    transforms.Normalize(mean=[.5], std=[.5])\n", "])"]}, {"cell_type": "markdown", "id": "0e321fbc", "metadata": {}, "source": ["Then, using the cell below, we can initialize a `Dataset` object based on the data that we have just downloaded."]}, {"cell_type": "code", "execution_count": null, "id": "de47c6cd", "metadata": {}, "outputs": [], "source": ["train_dataset = MedMNISTData(dataset, transform=data_transform)"]}, {"cell_type": "markdown", "id": "f3e42e1e", "metadata": {}, "source": ["The code below visualizes the first sample from the data set."]}, {"cell_type": "code", "execution_count": null, "id": "37f2133a", "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "plt.imshow(train_dataset[0]['img'].squeeze(), cmap='gray')\n", "plt.title('Label {}'.format(train_dataset[0]['label']))\n", "plt.show()"]}, {"cell_type": "markdown", "id": "d08a15bf", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "  \u2328\ufe0f <b>Exercise</b>: \u2753 Visualize a number of random samples from the dataset. What is their corresponding label?\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "id": "98303a84", "metadata": {"lines_to_next_cell": 2, "tags": ["student"]}, "outputs": [], "source": []}, {"cell_type": "markdown", "id": "4b87ea93", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "    \u2328\ufe0f <b>Exercise</b>: \u2753 Make a <code>val_dataset</code> and a <code>test_dataset</code> class for the validation and test set, respectively. Verify that these have 524 and 624 samples.\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "id": "bfd25a2d", "metadata": {"lines_to_next_cell": 2, "tags": ["student"]}, "outputs": [], "source": []}, {"cell_type": "markdown", "id": "bdb99ffc", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["## Dataloaders\n", "\n", "Now that we have a dataset, we can build a dataloader that automatically generates batches with given size. As input it uses one of the data sets constructed in the previous section. Here, the batch size is 32. We shuffle all samples so that each minibatch is different."]}, {"cell_type": "code", "execution_count": null, "id": "aba2b646", "metadata": {}, "outputs": [], "source": ["train_dataloader = monai.data.DataLoader(train_dataset, batch_size=32, shuffle=True)"]}, {"cell_type": "markdown", "id": "81932f09", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "    \u2328\ufe0f <b>Exercise</b>: \u2753 Also initialize a <a href='https://docs.monai.io/en/stable/data.html#dataloader'>dataloader</a> for the validation set and the test set. Call these <code>val_dataloader</code> and <code>test_dataloader</code>\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "id": "bc233b34", "metadata": {"lines_to_next_cell": 2, "tags": ["student"]}, "outputs": [], "source": []}, {"cell_type": "markdown", "id": "b53e9619", "metadata": {}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "    \u2328\ufe0f <b>Exercise</b>: \u2753 With these settings, will this dataloader support batch gradient descent, mini-batch gradient descent or stochastic gradient descent?\n", "</div>"]}, {"cell_type": "markdown", "id": "9bb30859", "metadata": {"tags": ["student"]}, "source": ["Answer:"]}, {"cell_type": "markdown", "id": "ebea9e7f", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["## The network\n", "Now our data pre-processing is all set up, we can define our neural network architecture. It is conventional to code neural networks as a <code>torch.nn.Module</code> object, where the <code>init</code> function defines the model's layers, and the <code>forward</code> function defines how data is fed through the network.\n", "Note that this network is built up from convolution layers, pooling layers, and the (fully connected) linear layers that we just used in the PyTorch section."]}, {"cell_type": "code", "execution_count": null, "id": "7a17e239", "metadata": {}, "outputs": [], "source": ["import torch.nn as nn\n", "import torch.nn.functional as F\n", "\n", "class Net(nn.Module):\n", "    def __init__(self):\n", "        super(Net, self).__init__()\n", "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)\n", "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n", "        self.fc1 = nn.Linear(in_features=9216, out_features=128)\n", "        self.fc2 = nn.Linear(in_features=128, out_features=1)\n", "\n", "    def forward(self, x):\n", "        x = self.conv1(x)\n", "        x = F.relu(x)\n", "        x = self.conv2(x)\n", "        x = F.relu(x)\n", "        x = F.max_pool2d(x, 2)\n", "        x = torch.flatten(x, 1)\n", "        x = self.fc1(x)\n", "        x = F.relu(x)\n", "        output = self.fc2(x)\n", "        return output\n", "    \n", "net = Net()"]}, {"cell_type": "markdown", "id": "a4ebe19a", "metadata": {}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "    \u2328\ufe0f <b>Exercise</b>: \u2753 How many layers does this network have? And how many weights?\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "id": "3d7cc1b3", "metadata": {"lines_to_next_cell": 2, "tags": ["student"]}, "outputs": [], "source": []}, {"cell_type": "markdown", "id": "16d1aa7f", "metadata": {}, "source": ["Move the model to the GPU."]}, {"cell_type": "code", "execution_count": null, "id": "2b0c15e0", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["model = Net().to(gpu)"]}, {"cell_type": "markdown", "id": "98d688e0", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["To train our network, we should again select an **optimizer** and a **loss** function. \n", "- A very common option is to use the Adam optimizer, which is an adaptive version of stochastic gradient descent. \n", "- Because we are solving a classification problem, a good loss function is binary cross-entropy. Here, we use `BCEWithLogitsLoss`, which operates directly on the output of the network (its logits) and integrates a sigmoid activation function. "]}, {"cell_type": "code", "execution_count": null, "id": "92a3d8d9", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["optimizer = torch.optim.Adam(model.parameters(), lr=3e-4) \n", "loss_function = torch.nn.BCEWithLogitsLoss()"]}, {"cell_type": "markdown", "id": "0eac53d3", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["## Training procedure for classification"]}, {"cell_type": "markdown", "id": "ae48230e", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["Now we have all the ingredients in place to start training our network. Easiest is to define a train function that performs the training procedure. In addition to a forward and backward pass with the training data, we want to perform a validation loop every $N$ epochs, using unseen data."]}, {"cell_type": "code", "execution_count": null, "id": "8015e5bf", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["from tqdm import tqdm\n", "\n", "def train_medmnist(model, train_dataloader, val_dataloader, optimizer, epochs, device=gpu, val_freq=1):\n", "    train_loss = []\n", "    val_loss = []\n", "\n", "    for epoch in tqdm(range(epochs)):\n", "        model.train()\n", "        steps = 0\n", "        epoch_loss = 0\n", "\n", "        for batch in train_dataloader:\n", "            optimizer.zero_grad()\n", "            images = batch['img'].float().to(device)\n", "            labels = batch['label'].float().to(device)\n", "            output = model(images) \n", "            loss = loss_function(output, labels)\n", "            epoch_loss += loss.item()\n", "            loss.backward()\n", "            optimizer.step()\n", "            steps += 1\n", "           \n", "        train_loss.append(epoch_loss/steps)\n", "\n", "        # validation loop\n", "        if epoch % val_freq == 0:\n", "            steps = 0\n", "            val_epoch_loss = 0\n", "            model.eval()\n", "            for batch in val_dataloader:\n", "                images = batch['img'].float().to(device)\n", "                labels = batch['label'].float().to(device)\n", "                output = model(images) \n", "                loss = loss_function(output, labels)\n", "                val_epoch_loss += loss.item()\n", "                steps += 1\n", "            val_loss.append(val_epoch_loss/steps)\n", "\n", "    return train_loss, val_loss, model"]}, {"cell_type": "markdown", "id": "0a86c3b5", "metadata": {}, "source": ["Train your (maybe?) first convolutional neural network! Time to get a coffee, this might take a few minutes.<br> <img src=\"https://i.redd.it/j586af7nxvu41.jpg\" width=\"400px\"></img>"]}, {"cell_type": "code", "execution_count": null, "id": "854391a3", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["val_freq = 10\n", "n_epochs = 100\n", "train_loss, val_loss, model = train_medmnist(model, train_dataloader, val_dataloader, optimizer, epochs=n_epochs, val_freq=val_freq)"]}, {"cell_type": "markdown", "id": "2a560b13", "metadata": {}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "    \u2328\ufe0f <b>Exercise</b>: \u2753 Visualize the training and validation loss using Matplotlib. What do you see? Did your model overfit?\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "id": "1b06b62b", "metadata": {"lines_to_next_cell": 2, "tags": ["student"]}, "outputs": [], "source": []}, {"cell_type": "markdown", "id": "c191ef43", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["## Part 5e: Performance evaluation\n", "By now, you have a trained version of the CNN, that should be able to distinguish between (very small) X-ray images showing pneumonia or not. For classification tasks, the performance is often measured in terms of specificity and sensitivity, as shown in the diagram below:\n", "\n", "<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Sensitivity_and_specificity_1.01.svg/330px-Sensitivity_and_specificity_1.01.svg.png />\n", "\n", "For this model, we will make an ROC curve to assess the performance."]}, {"cell_type": "code", "execution_count": null, "id": "d4bb6422", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["from sklearn.metrics import roc_curve, auc"]}, {"cell_type": "code", "execution_count": null, "id": "b620d4c1", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["def validation_results_ROC(model, dataloader):\n", "    for data in dataloader:\n", "        images = data['img'].float().to(gpu)\n", "        labels = data['label']\n", "        with torch.no_grad():\n", "            output = model(images).cpu()\n", "        fpr, tpr, _ = roc_curve(labels, output.squeeze(1))\n", "        print(auc(fpr, tpr))\n", "        plt.plot(fpr,tpr)\n", "        plt.xlabel('False positive rate')\n", "        plt.ylabel('False negative rate')\n", "        plt.plot([0,1], [0,1], 'r--')"]}, {"cell_type": "markdown", "id": "75aaf4b1", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "    \u2328\ufe0f <b>Exercise</b>: \u2753 Does the model perform well for pneumonia classification? Calculate the area under the curve for the validation set as well as for the test set.\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "id": "4374bdea", "metadata": {"lines_to_next_cell": 2, "tags": ["student"]}, "outputs": [], "source": []}, {"cell_type": "markdown", "id": "d6170b85", "metadata": {"pycharm": {"name": "#%% md\n"}}, "source": ["For improvement of the model, it is useful to visualize some inputs and the corresponding predictions of the network."]}, {"cell_type": "code", "execution_count": null, "id": "82a11f70", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["def validation_results_visualize(model, dataset):\n", "    index = np.random.randint(0, len(dataset))\n", "    image = dataset[index]['img']\n", "    plt.imshow(image.numpy().squeeze(), cmap='gray')\n", "    image = image.float().to(gpu)\n", "    label = dataset[index]['label'].item()\n", "    with torch.no_grad():\n", "        output = F.sigmoid(model(image.unsqueeze(0)))\n", "    plt.title(f'Ground truth: {label}, prediction: {int(output)}')"]}, {"cell_type": "code", "execution_count": null, "id": "9671c2f5", "metadata": {"pycharm": {"name": "#%%\n"}}, "outputs": [], "source": ["validation_results_visualize(model, val_dataset)"]}, {"cell_type": "markdown", "id": "bac6d299", "metadata": {}, "source": ["<div style='background-color:rgba(80,255,80,0.4); padding:20px'>\n", "    \u2328\ufe0f <b>Exercise</b>: \u2753 Select a 3D dataset from MedMNIST (NoduleMNIST3D or VesselMNIST3D) and train and validate a model for that set. Consider which changes you have to make.\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "id": "e9dd4c0a", "metadata": {"tags": ["student"]}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 5}