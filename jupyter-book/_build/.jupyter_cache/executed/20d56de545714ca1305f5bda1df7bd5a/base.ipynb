{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3161b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⌨️ add path:\n",
    "data_path = \"../data/Tutorial_3/ribs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2cd1108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please update your data path to an existing folder.\n"
     ]
    }
   ],
   "source": [
    "# check if data_path exists:\n",
    "import os\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    print(\"Please update your data path to an existing folder.\")\n",
    "elif not set([\"train\", \"val\", \"test\"]).issubset(set(os.listdir(data_path))):\n",
    "    print(\"Please update your data path to the correct folder (should contain train, val and test folders).\")\n",
    "else:\n",
    "    print(\"Congrats! You selected the correct folder :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48721cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (0.19.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image) (2021.7.2)\r\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image) (2.6.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image) (22.0)\r\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image) (2.19.3)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image) (1.7.3)\r\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image) (9.4.0)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image) (1.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image) (1.21.5)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (0.16.6)\r\n",
      "Requirement already satisfied: PyYAML in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (6.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (8.0.4)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (2.28.1)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (4.24.4)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (1.45.0)\r\n",
      "Requirement already satisfied: setproctitle in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (1.3.3)\r\n",
      "Requirement already satisfied: setuptools in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (65.6.3)\r\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (3.1.43)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (4.4.0)\r\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (1.4.4)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (5.9.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from Click!=8.0.0,>=7.1->wandb) (4.11.3)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.1->wandb) (3.11.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: monai in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (1.1.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=1.8 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from monai) (1.13.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from monai) (1.21.5)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from torch>=1.8->monai) (4.4.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Install additional packages required for this tutorial\n",
    "!pip install scikit-image\n",
    "!pip install wandb\n",
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "718448c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjelmerwolterink\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349377c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/jmwolterink/Library/CloudStorage/OneDrive-UniversityofTwente/Teaching/DLMIA_2023_2024/dlmia-2024/notebooks/Tutorial3_Segmentation/wandb/run-20240424_151937-v7vx8g0y\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mExample run\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jelmerwolterink/Example%20project\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jelmerwolterink/Example%20project/runs/v7vx8g0y\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project='Example project', name='Example run', config={'dataset': 'VinDr-RibCXR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1458dbd6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.015 MB of 0.015 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.015 MB of 0.015 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.015 MB of 0.015 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Accuracy ▂▇██▂▁▆▅▄▄█▅█▆▇▆▂▄▄▅▄▆▆▂▄▂▃▆▅▆▂▄▄▂▅▄█▂█▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     Loss ▅▁▂▅▅▄▄▂▂▄▆▄▆▇▆▆▅▇▇▃▄▅▇▃▁▅▄█▁█▆▂▂▆▆▃▂▁▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Accuracy 0.23118\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     Loss 0.68557\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mExample run\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/jelmerwolterink/Example%20project/runs/v7vx8g0y\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/jelmerwolterink/Example%20project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240424_151937-v7vx8g0y/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# time.sleep(1) makes the script wait for 1 second, so the full script takes about 60 seconds to finish\n",
    "for step in range(60):\n",
    "    wandb.log({'Loss': random.random(), 'Accuracy': random.random()})\n",
    "    time.sleep(1)\n",
    "    \n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a3fbe4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import monai\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "def build_dict_ribs(data_path, mode='train'):\n",
    "    \"\"\"\n",
    "    This function returns a list of dictionaries, each dictionary containing the keys 'img' and 'mask' \n",
    "    that returns the path to the corresponding image.\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): path to the root folder of the data set.\n",
    "        mode (str): subset used. Must correspond to 'train', 'val' or 'test'.\n",
    "        \n",
    "    Returns:\n",
    "        (List[Dict[str, str]]) list of the dictionaries containing the paths of X-ray images and masks.\n",
    "    \"\"\"\n",
    "    # test if mode is correct\n",
    "    if mode not in [\"train\", \"val\", \"test\"]:\n",
    "        raise ValueError(f\"Please choose a mode in ['train', 'val', 'test']. Current mode is {mode}.\")\n",
    "    \n",
    "    # define empty dictionary\n",
    "    dicts = []\n",
    "    # list all .png files in directory, including the path\n",
    "    paths_xray = glob.glob(os.path.join(data_path, mode, 'img', '*.png'))\n",
    "    # make a corresponding list for all the mask files\n",
    "    for xray_path in paths_xray:\n",
    "        if mode == 'test':\n",
    "            suffix = 'val'\n",
    "        else:\n",
    "            suffix = mode\n",
    "        # find the binary mask that belongs to the original image, based on indexing in the filename\n",
    "        image_index = os.path.split(xray_path)[1].split('_')[-1].split('.')[0]\n",
    "        # define path to mask file based on this index and add to list of mask paths\n",
    "        mask_path = os.path.join(data_path, mode, 'mask', f'VinDr_RibCXR_{suffix}_{image_index}.png')\n",
    "        if os.path.exists(mask_path):\n",
    "            dicts.append({'img': xray_path, 'mask': mask_path})\n",
    "    return dicts\n",
    "\n",
    "class LoadRibData(monai.transforms.Transform):\n",
    "    \"\"\"\n",
    "    This custom Monai transform loads the data from the rib segmentation dataset.\n",
    "    Defining a custom transform is simple; just overwrite the __init__ function and __call__ function.\n",
    "    \"\"\"\n",
    "    def __init__(self, keys=None):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = Image.open(sample['img']).convert('L') # import as grayscale image\n",
    "        image = np.array(image, dtype=np.uint8)\n",
    "        mask = Image.open(sample['mask']).convert('L') # import as grayscale image\n",
    "        mask = np.array(mask, dtype=np.uint8)\n",
    "        # mask has value 255 on rib pixels. Convert to binary array\n",
    "        mask[np.where(mask==255)] = 1\n",
    "        return {'img': image, 'mask': mask, 'img_meta_dict': {'affine': np.eye(2)}, \n",
    "                'mask_meta_dict': {'affine': np.eye(2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c098e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# construct list of dictionaries\n",
    "train_dict_list = build_dict_ribs(data_path, mode='train')\n",
    "# construct CacheDataset from list of paths + transform\n",
    "train_dataset = monai.data.CacheDataset(train_dict_list, transform=LoadRibData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "976562e8",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<fstring>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<fstring>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    (train_dataset.__len__()=)\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "val_dict_list = build_dict_ribs(data_path, mode='val')\n",
    "test_dict_list = build_dict_ribs(data_path, mode='test')\n",
    "val_dataset = monai.data.CacheDataset(val_dict_list, transform=LoadRibData())\n",
    "test_dataset = monai.data.CacheDataset(test_dict_list, transform=LoadRibData())\n",
    "\n",
    "print(f'{train_dataset.__len__()=}')\n",
    "print(f'{val_dataset.__len__()=}')\n",
    "print(f'{test_dataset.__len__()=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3682cc73",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<fstring>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<fstring>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    (img.shape=)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    sample = train_dataset[i]\n",
    "    img = sample['img']\n",
    "    mask = sample['mask']\n",
    "    print(f'{img.shape=}, {mask.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f24cf9d2",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_79722/973639868.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# dataset[[1, 3, 4]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# if existing in cache, try to get the index in cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0mcache_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hash_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_num\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# support negative index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m             \u001b[0mcache_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "bins = np.linspace(0, 255, 50)\n",
    "for i in range(5):\n",
    "    sample = train_dataset[i]\n",
    "    img = sample['img']\n",
    "    img = img.flatten()\n",
    "    plt.hist(img, bins, alpha=0.5, label=i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85f29bd4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_rib_sample(sample, title=None):\n",
    "    # Visualize the x-ray and overlay the mask, using the dictionary as input\n",
    "    image = np.squeeze(sample['img'])\n",
    "    mask = np.squeeze(sample['mask'])\n",
    "    plt.figure(figsize=[10,7])\n",
    "    plt.imshow(image, 'gray')\n",
    "    overlay_mask = np.ma.masked_where(mask == 0, mask == 1)\n",
    "    plt.imshow(overlay_mask, 'Greens', alpha = 0.7, clim=[0,1], interpolation='nearest')\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d075b025",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_79722/2524094290.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvisualize_rib_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# dataset[[1, 3, 4]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# if existing in cache, try to get the index in cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0mcache_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hash_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_num\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# support negative index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m             \u001b[0mcache_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "sample_dict = train_dataset[0]\n",
    "visualize_rib_sample(sample_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b060d96a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_79722/1625175677.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This picks a random sample, but you can change this value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msample_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvisualize_rib_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Original sample\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "# Load sample\n",
    "index = np.random.choice(np.arange(len(train_dataset))) # This picks a random sample, but you can change this value\n",
    "sample_dict = train_dataset[index]\n",
    "visualize_rib_sample(sample_dict, title=\"Original sample\")\n",
    "\n",
    "# Add channels\n",
    "add_channels_transform = monai.transforms.AddChanneld(keys=['img', 'mask']) # Initialize the transform\n",
    "channels_sample_dict = add_channels_transform(sample_dict) # Apply the transform\n",
    "print(\"Size of the image before AddChanneld transform\", sample_dict[\"img\"].shape)\n",
    "print(\"Size of the image after AddChanneld transform\", channels_sample_dict[\"img\"].shape)\n",
    "\n",
    "# Random flip\n",
    "# here we define the keys, the probability that the flip is performed and the axis to flip over\n",
    "random_flip_transform = monai.transforms.RandFlipd(keys=['img', 'mask'], prob=1, spatial_axis=1)\n",
    "# We put a probability of 1 to always flip the image for visualization purposes.\n",
    "# Please DO NOT DO THAT in the rest of the notebook.\n",
    "flipped_sample_dict = random_flip_transform(channels_sample_dict)\n",
    "visualize_rib_sample(flipped_sample_dict, title=\"(Not quite randomly) flipped sample\")\n",
    "\n",
    "# Random rotation\n",
    "# Here we define the keys in the dictionary that contain the data, the rotation range, but also the interpolation mode. \n",
    "# The interpolation mode defines how new pixel values for the rotated image are computed. \n",
    "# Note that these differ between mask and image, as we want to keep binary labels for the masks, and (bi)linear interpolation\n",
    "# would result in scalar values between 0 and 1.\n",
    "random_rotation_transform = monai.transforms.RandRotated(keys=['img', 'mask'], range_x=np.pi/4, prob=1, mode=['bilinear', 'nearest'])\n",
    "rotated_sample_dict = random_rotation_transform(channels_sample_dict)\n",
    "visualize_rib_sample(rotated_sample_dict, title=\"Randomly rotated sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c93c513",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_79722/161091586.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create the composed transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0madd_channels_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddChanneld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Initialize the transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrandom_flip_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandFlipd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspatial_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# dataset[[1, 3, 4]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# if existing in cache, try to get the index in cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0mcache_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hash_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_num\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# support negative index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m             \u001b[0mcache_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "sample_dict = train_dataset[0]\n",
    "\n",
    "# Create the composed transform\n",
    "add_channels_transform = monai.transforms.AddChanneld(keys=['img', 'mask']) # Initialize the transform\n",
    "random_flip_transform = monai.transforms.RandFlipd(keys=['img', 'mask'], prob=1, spatial_axis=1)\n",
    "random_rotation_transform = monai.transforms.RandRotated(keys=['img', 'mask'], range_x=np.pi/4, prob=1, mode=['bilinear', 'nearest'])\n",
    "\n",
    "transforms = monai.transforms.Compose([\n",
    "    add_channels_transform,\n",
    "    random_flip_transform,\n",
    "    random_rotation_transform\n",
    "])\n",
    "\n",
    "# Apply this new single transform to sample_dict\n",
    "transformed_sample = transforms(sample_dict)\n",
    "visualize_rib_sample(transformed_sample, title=\"Transformed sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53bbc344",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/utils/deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "  warn_deprecated(obj, msg, warning_category)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_79722/4290777752.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mvisualize_rib_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Transformed sample {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# dataset[[1, 3, 4]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# if existing in cache, try to get the index in cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0mcache_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hash_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_num\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# support negative index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m             \u001b[0mcache_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "train_transform = monai.transforms.Compose([\n",
    "    LoadRibData(),\n",
    "    monai.transforms.AddChanneld(keys=['img', 'mask']),\n",
    "    monai.transforms.ScaleIntensityd(keys=['img'],minv=0, maxv=1),\n",
    "    monai.transforms.Zoomd(keys=['img', 'mask'], zoom=0.25, keep_size=False, mode=['bilinear', 'nearest']),\n",
    "    monai.transforms.RandFlipd(keys=['img', 'mask'], prob=0.5, spatial_axis=1),\n",
    "    monai.transforms.RandSpatialCropd(keys=['img', 'mask'], roi_size=[256,256], random_size=False)\n",
    "])\n",
    "\n",
    "train_dataset = monai.data.CacheDataset(train_dict_list, transform=train_transform)\n",
    "\n",
    "for i in range(5):\n",
    "    visualize_rib_sample(train_dataset[i], title=f\"Transformed sample {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d8b7268",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def from_compose_to_list(transform_compose):\n",
    "    \"\"\"\n",
    "    Transform an object monai.transforms.Compose in a list fully describing the transform.\n",
    "    /!\\ Random seed is not saved, then reproducibility is not enabled.\n",
    "    \"\"\"\n",
    "    from copy import deepcopy\n",
    "        \n",
    "    if not isinstance(transform_compose, monai.transforms.Compose):\n",
    "        raise TypeError(\"transform_compose should be a monai.transforms.Compose object.\")\n",
    "    \n",
    "    output_list = list()\n",
    "    for transform in transform_compose.transforms:\n",
    "        kwargs = deepcopy(vars(transform))\n",
    "        \n",
    "        # Remove attributes which are not arguments\n",
    "        args = list(transform.__init__.__code__.co_varnames[1: transform.__init__.__code__.co_argcount])\n",
    "        for key, obj in vars(transform).items():\n",
    "            if key not in args:\n",
    "                del kwargs[key]\n",
    "\n",
    "        output_list.append({\"class\": transform.__class__, \"kwargs\": kwargs})\n",
    "    return output_list\n",
    "\n",
    "def from_list_to_compose(transform_list):\n",
    "    \"\"\"\n",
    "    Transform a list in the corresponding monai.transforms.Compose object.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not isinstance(transform_list, list):\n",
    "        raise TypeError(\"transform_list should be a list.\")\n",
    "    \n",
    "    pre_compose_list = list()\n",
    "    \n",
    "    for transform_dict in transform_list:\n",
    "        if not isinstance(transform_dict, dict) or 'class' not in transform_dict or 'kwargs' not in transform_dict:\n",
    "            raise TypeError(\"transform_list should only contains dicts with keys ['class', 'kwargs']\")\n",
    "        \n",
    "        try:\n",
    "            transform = transform_dict['class'](**transform_dict['kwargs'])\n",
    "        except TypeError: # Classes have been converted to str after saving\n",
    "            transform = eval(transform_dict['class'].replace(\"__main__.\", \"\"))(**transform_dict['kwargs'])\n",
    "            \n",
    "        pre_compose_list.append(transform)\n",
    "        \n",
    "    return monai.transforms.Compose(pre_compose_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "207f3265",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_79722/2591026275.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, num_workers, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"worker_init_fn\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker_init_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m--> 108\u001b[0;31m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "train_loader = monai.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "print(next(iter(train_loader))['img'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "008074c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_79722/4167519062.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCacheDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvalidation_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "validation_dict = build_dict_ribs(data_path, mode='val')\n",
    "\n",
    "validation_transforms = monai.transforms.Compose([\n",
    "    LoadRibData(),\n",
    "    monai.transforms.AddChanneld(keys=['img', 'mask']),\n",
    "    monai.transforms.ScaleIntensityd(keys=['img'],minv=0, maxv=1),\n",
    "    monai.transforms.Resized(keys=['img', 'mask'], spatial_size=[256,256])\n",
    "])\n",
    "validation_data = monai.data.CacheDataset(validation_dict, transform=validation_transforms)\n",
    "validation_loader = monai.data.DataLoader(validation_data, batch_size=16)\n",
    "print(next(iter(validation_loader))['img'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4382d05e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The used device is cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'The used device is {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb82fc57",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = monai.networks.nets.UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(8, 16, 32, 64, 128),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "002d08ff",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U-Net has 5 layers (see \"channels\" parameter) and 406804 parameters\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'U-Net has 5 layers (see \"channels\" parameter) and {num_params} parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce991218",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_function =  monai.losses.DiceLoss(sigmoid=True, batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca1f2449",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "009a314a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_79722/1054519189.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m'transform'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfrom_compose_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     }\n\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "run = wandb.init(\n",
    "    project='tutorial3_segmentation',\n",
    "    name='test',\n",
    "    config={\n",
    "        'loss function': str(loss_function), \n",
    "        'lr': optimizer.param_groups[0][\"lr\"],\n",
    "        'transform': from_compose_to_list(train_transform),\n",
    "        'batch_size': train_loader.batch_size,\n",
    "    }\n",
    ")\n",
    "# Do not hesitate to enrich this list of settings to be able to correctly keep track of your experiments!\n",
    "# For example you should add information on your model...\n",
    "\n",
    "run_id = run.id # We remember here the run ID to be able to write the evaluation metrics\n",
    "\n",
    "def wandb_masks(mask_output, mask_gt):\n",
    "    \"\"\" Function that generates a mask dictionary in format that W&B requires \"\"\"\n",
    "\n",
    "    # Apply sigmoid to model ouput and round to nearest integer (0 or 1)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    mask_output = sigmoid(mask_output)\n",
    "    mask_output = torch.round(mask_output)\n",
    "\n",
    "    # Transform masks to numpy arrays on CPU\n",
    "    # Note: .squeeze() removes all dimensions with a size of 1 (here, it makes the tensors 2-dimensional)\n",
    "    # Note: .detach() removes a tensor from the computational graph to prevent gradient computation for it\n",
    "    mask_output = mask_output.squeeze().detach().cpu().numpy()\n",
    "    mask_gt = mask_gt.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    # Create mask dictionary with class label and insert masks\n",
    "    class_labels = {1: 'ribs'}\n",
    "    masks = {\n",
    "        'predictions': {'mask_data': mask_output, 'class_labels': class_labels},\n",
    "        'ground truth': {'mask_data': mask_gt, 'class_labels': class_labels}\n",
    "    }\n",
    "    return masks\n",
    "\n",
    "def log_to_wandb(epoch, train_loss, val_loss, batch_data, outputs):\n",
    "    \"\"\" Function that logs ongoing training variables to W&B \"\"\"\n",
    "\n",
    "    # Create list of images that have segmentation masks for model output and ground truth\n",
    "    log_imgs = [wandb.Image(img, masks=wandb_masks(mask_output, mask_gt)) for img, mask_output,\n",
    "                mask_gt in zip(batch_data['img'], outputs, batch_data['mask'])]\n",
    "\n",
    "    # Send epoch, losses and images to W&B\n",
    "    wandb.log({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss, 'results': log_imgs})\n",
    "    \n",
    "for epoch in tqdm(range(200)):\n",
    "    \n",
    "    # training\n",
    "    model.train()    \n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader: \n",
    "        step += 1\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_data[\"img\"].float().to(device))\n",
    "        loss = loss_function(outputs, batch_data[\"mask\"].to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    train_loss = epoch_loss/step\n",
    "    \n",
    "    # validation\n",
    "    step = 0\n",
    "    val_loss = 0\n",
    "    for batch_data in validation_loader:\n",
    "        step += 1\n",
    "        model.eval()\n",
    "        outputs = model(batch_data['img'].float().to(device))\n",
    "        loss = loss_function(outputs, batch_data['mask'].to(device))\n",
    "        val_loss+= loss.item()\n",
    "    val_loss = val_loss / step\n",
    "    log_to_wandb(epoch, train_loss, val_loss, batch_data, outputs)\n",
    "\n",
    "# Store the network parameters        \n",
    "torch.save(model.state_dict(), r'trainedUNet.pt')\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69615824",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def visual_evaluation(sample, model):\n",
    "    \"\"\"\n",
    "    Allow the visual inspection of one sample by plotting the X-ray image, the ground truth (green)\n",
    "    and the segmentation map produced by the network (red).\n",
    "    \n",
    "    Args:\n",
    "        sample (Dict[str, torch.Tensor]): sample composed of an X-ray ('img') and a mask ('mask').\n",
    "        model (torch.nn.Module): trained model to evaluate.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    inferer = monai.inferers.SlidingWindowInferer(roi_size=[256, 256])\n",
    "    discrete_transform = monai.transforms.AsDiscrete(logit_thresh=0.5, threshold_values=True)\n",
    "    Sigmoid = torch.nn.Sigmoid()\n",
    "    with torch.no_grad():\n",
    "        output = discrete_transform(Sigmoid(inferer(sample['img'].to(device), network=model).cpu())).squeeze()\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3, figsize = [12, 10])\n",
    "    # Plot X-ray image\n",
    "    ax[0].imshow(sample[\"img\"].squeeze(), 'gray')    \n",
    "    ax[1].imshow(sample[\"img\"].squeeze(), 'gray')\n",
    "    # Plot ground truth\n",
    "    mask = np.squeeze(sample['mask'])\n",
    "    overlay_mask = np.ma.masked_where(mask == 0, mask == 1)\n",
    "    ax[1].imshow(overlay_mask, 'Greens', alpha = 0.7, clim=[0,1], interpolation='nearest')\n",
    "    ax[1].set_title('Ground truth')\n",
    "    # Plot output\n",
    "    overlay_output = np.ma.masked_where(output < 0.1, output >0.99)\n",
    "    ax[2].imshow(sample['img'].squeeze(), 'gray')\n",
    "    ax[2].imshow(overlay_output, 'Reds', alpha = 0.7, clim=[0,1])\n",
    "    ax[2].set_title('Prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea446762",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_dict = build_dict_ribs(data_path, mode='test')\n",
    "test_transform = monai.transforms.Compose([\n",
    "        LoadRibData(),\n",
    "        monai.transforms.AddChanneld(keys=['img', 'mask']),\n",
    "        monai.transforms.ScaleIntensityd(keys=['img'],minv=0, maxv=1),\n",
    "        monai.transforms.Zoomd(keys=['img', 'mask'], zoom=0.25, keep_size=False, mode=['bilinear', 'nearest']),\n",
    "    ]\n",
    ")\n",
    "test_set = monai.data.CacheDataset(test_dict, transform=test_transform)\n",
    "test_loader = monai.data.DataLoader(test_set, batch_size=1)\n",
    "\n",
    "for sample in test_loader:\n",
    "    visual_evaluation(sample, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "825871d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric(dataloader, model, metric_fn):\n",
    "    \"\"\"\n",
    "    This function computes the average value of a metric for a data set.\n",
    "    \n",
    "    Args:\n",
    "        dataloader (monai.data.DataLoader): dataloader wrapping the dataset to evaluate.\n",
    "        model (torch.nn.Module): trained model to evaluate.\n",
    "        metric_fn (function): function computing the metric value from two tensors:\n",
    "            - a batch of outputs,\n",
    "            - the corresponding batch of ground truth masks.\n",
    "        \n",
    "    Returns:\n",
    "        (float) the mean value of the metric\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    inferer = monai.inferers.SlidingWindowInferer(roi_size=[256, 256])\n",
    "    discrete_transform = monai.transforms.AsDiscrete(threshold=0.5)\n",
    "    Sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    mean_value = 0\n",
    "    \n",
    "    for sample in dataloader:\n",
    "        with torch.no_grad():\n",
    "            output = discrete_transform(Sigmoid(inferer(sample['img'].to(device), network=model).cpu()))\n",
    "        mean_value += metric_fn(output, sample[\"mask\"])\n",
    "    \n",
    "    return (mean_value / len(dataloader)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f32c6e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_79722/489699043.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tutorial3_segmentation/{run_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run_id' is not defined"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(f\"tutorial3_segmentation/{run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d19c4c08",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_79722/2325283766.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmetric_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_meandice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dice\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dice on test set: {dice:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_79722/2620846242.py\u001b[0m in \u001b[0;36mcompute_metric\u001b[0;34m(dataloader, model, metric_fn)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mmean_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean_value\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "metric_fn = monai.metrics.compute_meandice\n",
    "dice = compute_metric(test_loader, model, metric_fn)\n",
    "run.summary[\"dice\"] = dice\n",
    "print(f\"Dice on test set: {dice:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25cbda29",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_79722/758283162.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmetric_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_hausdorff_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mHausdorff_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Hausdorff_dist\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHausdorff_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Hausdorff distance on test set: {Hausdorff_dist:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_79722/2620846242.py\u001b[0m in \u001b[0;36mcompute_metric\u001b[0;34m(dataloader, model, metric_fn)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mmean_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean_value\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "metric_fn = monai.metrics.compute_hausdorff_distance\n",
    "Hausdorff_dist = compute_metric(test_loader, model, metric_fn)\n",
    "run.summary[\"Hausdorff_dist\"] = Hausdorff_dist\n",
    "print(f\"Hausdorff distance on test set: {Hausdorff_dist:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "effd2b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "\n",
    "def make_dummy_sample(sample):\n",
    "    M = sample['mask'].squeeze()\n",
    "    labels = measure.label(M)\n",
    "    dummy_labels = np.zeros((labels.shape[0], labels.shape[1]))\n",
    "    for i in np.unique(labels):\n",
    "        if i > 0:\n",
    "            mask_locs = np.where(labels == i)\n",
    "            limits = [np.min(mask_locs[0]), np.max(mask_locs[0]), np.min(mask_locs[1]), np.max(mask_locs[1])]\n",
    "            dummy_labels[limits[0]:limits[1], limits[2]:limits[3]] = 1\n",
    "    return torch.tensor(dummy_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3dbb0e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_79722/2614710951.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvisualize_rib_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'original mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvisualize_rib_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmake_dummy_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dummy segmentation masks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# dataset[[1, 3, 4]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# if existing in cache, try to get the index in cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0mcache_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hash_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_num\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# support negative index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m             \u001b[0mcache_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "sample = test_set[0]\n",
    "visualize_rib_sample(sample, title = 'original mask')\n",
    "visualize_rib_sample({'img': sample['img'], 'mask': make_dummy_sample(sample)}, title = 'dummy segmentation masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe10de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric_dummy(dataloader, metric_fn):\n",
    "    \"\"\"\n",
    "    This function computes the average value of a metric for a data set using the dummy segmentation masks\n",
    "    \n",
    "    Args:\n",
    "        dataloader (monai.data.DataLoader): dataloader wrapping the dataset to evaluate.\n",
    "        metric_fn (function): function computing the metric value from two tensors:\n",
    "            - a batch of outputs,\n",
    "            - the corresponding batch of ground truth masks.\n",
    "        \n",
    "    Returns:\n",
    "        (float) the mean value of the metric\n",
    "    \"\"\"\n",
    "    \n",
    "    mean_value = 0\n",
    "    A = monai.transforms.AddChannel()\n",
    "    \n",
    "    for sample in dataloader:\n",
    "        output = make_dummy_sample(sample)\n",
    "        mean_value += metric_fn(A(A(output)), sample[\"mask\"])\n",
    "    \n",
    "    return (mean_value / len(dataloader)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e76a97a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_79722/2878529152.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Mean Dice: {compute_metric_dummy(test_loader, monai.metrics.compute_meandice):.3f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_79722/797961195.py\u001b[0m in \u001b[0;36mcompute_metric_dummy\u001b[0;34m(dataloader, metric_fn)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmean_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean_value\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "print(f'Mean Dice: {compute_metric_dummy(test_loader, monai.metrics.compute_meandice):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2f51456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⌨️ code your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}