{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea41c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f14fd312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image could not be found. Please check that the file TEV1P1CTI.mhd can be found in \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_file = os.path.join(data_path, r'TEV1P1CTI.mhd')\n",
    "\n",
    "if not os.path.exists(image_file):\n",
    "    print(f'The image could not be found. '\n",
    "          f'Please check that the file TEV1P1CTI.mhd can be found in {data_path}')\n",
    "else:\n",
    "    image = sitk.ReadImage(image_file)\n",
    "    image_array = sitk.GetArrayFromImage(image)\n",
    "    image_array = np.swapaxes(image_array, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427d7b3e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_49704/2552605338.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Only consider one image slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Use Scipy to downsample the image by a factor 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_array' is not defined"
     ]
    }
   ],
   "source": [
    "import scipy.ndimage as scnd\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Only consider one image slice\n",
    "image_slice = image_array[:, :, 20].squeeze().transpose()\n",
    "\n",
    "# Use Scipy to downsample the image by a factor 4\n",
    "image_slice = scnd.zoom(image_slice, 0.25)\n",
    "\n",
    "plt.title(\"Downsampled slice\")\n",
    "plt.imshow(image_slice, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb0ec27",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "g = np.array([[0, 0, 0],\n",
    "              [0, 0, 1],\n",
    "              [0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75d818d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_slice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_49704/2050052134.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiltered_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_slice' is not defined"
     ]
    }
   ],
   "source": [
    "filtered_image = image_slice\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1) \n",
    "\n",
    "for level in range(20): # The kernel is applied 20 times\n",
    "    filtered_image = scnd.correlate(filtered_image, g, mode='constant', cval=0)\n",
    "    ax.imshow(filtered_image, cmap='gray', clim=[-300, 450])\n",
    "    ax.set_title('Applied {} times'.format(level))\n",
    "    display(fig)\n",
    "    \n",
    "    clear_output(wait = True)\n",
    "    plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38608f6a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_slice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_49704/3941258956.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfiltered_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_slice' is not defined"
     ]
    }
   ],
   "source": [
    "filtered_image = image_slice\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "for level in range(20): # The kernel is applied 20 times\n",
    "    filtered_image = scnd.convolve(filtered_image, g, mode='constant', cval=0)\n",
    "    ax.imshow(filtered_image, cmap='gray', clim=[-300, 450])\n",
    "    ax.set_title('Applied {} times'.format(level))\n",
    "    display(fig)\n",
    "    \n",
    "    clear_output(wait = True)\n",
    "    plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "381c0511",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[1 2 3]\n",
      "<class 'torch.Tensor'>\n",
      "tensor([1, 2, 3])\n",
      "<class 'numpy.ndarray'>\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Start with a NumPy array\n",
    "a = np.array([1, 2, 3])\n",
    "print(type(a))\n",
    "print(a)\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "a_t = torch.from_numpy(a)\n",
    "print(type(a_t))\n",
    "print(a_t)\n",
    "\n",
    "# Convert back to NumPy array\n",
    "a = a_t.numpy()\n",
    "print(type(a))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "909cfe93",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # CUDA\n",
    "    gpu = torch.device('cuda:0')\n",
    "else:\n",
    "    # MacBook with >M1 chip\n",
    "    gpu = torch.device('mps')\n",
    "\n",
    "try:\n",
    "    a_t = a_t.to(device=gpu)\n",
    "except Exception:\n",
    "    print(\"No GPU was found on your machine.\"\n",
    "          \"Use colab or JupyterLab to access a GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4f1c4d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, mps:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_49704/1424124837.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_t\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, mps:0 and cpu!"
     ]
    }
   ],
   "source": [
    "summed = a_t + torch.Tensor([4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce6f943a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "summed = a_t + torch.Tensor([4, 5, 6]).to(device=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d04225e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.5733e-01,  8.3332e-01,  1.6799e+00,  ..., -2.5142e+00,\n",
      "          2.0756e-01, -1.1494e+00],\n",
      "        [ 2.5139e-01, -1.0730e+00, -5.9246e-01,  ...,  7.0610e-04,\n",
      "         -4.5357e-01, -1.9172e+00],\n",
      "        [ 8.1169e-01,  1.7883e+00, -7.0340e-01,  ...,  9.0216e-01,\n",
      "         -1.2327e+00, -8.7903e-01],\n",
      "        ...,\n",
      "        [ 5.1994e-01, -1.6500e+00,  2.3617e-01,  ..., -6.8722e-01,\n",
      "         -1.2570e+00,  2.0804e-01],\n",
      "        [-6.2757e-01,  5.1785e-01, -1.7138e-01,  ..., -1.6879e-02,\n",
      "          6.6434e-01,  1.1214e+00],\n",
      "        [ 1.8146e+00,  4.1044e-01,  6.0555e-01,  ...,  1.5129e+00,\n",
      "          6.7483e-01,  4.6970e-01]], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/torch/_tensor_str.py:116: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  tensor_view, torch.isfinite(tensor_view) & tensor_view.ne(0)\n"
     ]
    }
   ],
   "source": [
    "rn = torch.randn(1000, 1000, device=gpu)\n",
    "print(rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e3da2ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_slice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_49704/1120085648.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimage_slice_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m g_t = torch.tensor([[0, 0, 0],\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_slice' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "image_slice_t = torch.from_numpy(image_slice).float()\n",
    "\n",
    "g_t = torch.tensor([[0, 0, 0],\n",
    "                    [0, 0, 1],\n",
    "                    [0, 0, 0]]).float()\n",
    "\n",
    "# We reshape the image because the conv2d function expects [batch_size, channels, width, height] inputs and kernels. You'll see \n",
    "# later what we mean with batch_size and channels.\n",
    "filtered_image_t = F.conv2d(image_slice_t.reshape((1, 1, 128, 128)), g_t.reshape((1, 1, 3, 3)), padding='same').squeeze()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1) \n",
    "for level in range(1, 20):\n",
    "    filtered_image_t = F.conv2d(filtered_image_t.reshape((1, 1, 128, 128)), g_t.reshape((1, 1, 3, 3)), padding='same').squeeze()\n",
    "    ax.imshow(filtered_image_t.numpy(), cmap='gray', clim=[-300, 450])\n",
    "    ax.set_title('Applied {} times'.format(level))\n",
    "    display(fig)\n",
    "    \n",
    "    clear_output(wait = True)\n",
    "    plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "792f175a",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_slice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_49704/3457085804.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_slice_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m### APPROACH ONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m g_t = torch.tensor([[0, 0, 0, 0, 0],\n\u001b[1;32m      5\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_slice' is not defined"
     ]
    }
   ],
   "source": [
    "image_slice_t = torch.from_numpy(image_slice).float()\n",
    "\n",
    "### APPROACH ONE\n",
    "g_t = torch.tensor([[0, 0, 0, 0, 0],\n",
    "                    [0, 0, 0, 0, 0],\n",
    "                    [0, 0, 0, 0, 0],\n",
    "                    [0, 0, 0, 0, 0],\n",
    "                    [0, 1, 0, 0, 0]]).float()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1) \n",
    "filtered_image_t = F.conv2d(image_slice_t.reshape((1, 1, 128, 128)), g_t.reshape((1, 1, 5, 5)), padding='same').squeeze()\n",
    "ax.imshow(filtered_image_t.numpy(), cmap='gray', clim=[-300, 450]);  \n",
    "ax.set_title('In one step')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### APPROACH TWO\n",
    "g_right = torch.tensor([[0, 0, 0],\n",
    "                        [1, 0, 0],\n",
    "                        [0, 0, 0]]).float()\n",
    "\n",
    "g_up = torch.tensor([[0, 0, 0],\n",
    "                        [0, 0, 0],\n",
    "                        [0, 1, 0]]).float()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1) \n",
    "filtered_image_t = F.conv2d(image_slice_t.reshape((1, 1, 128, 128)), g_up.reshape((1, 1, 3, 3)), padding='same').squeeze()\n",
    "filtered_image_t = F.conv2d(filtered_image_t.reshape((1, 1, 128, 128)), g_up.reshape((1, 1, 3, 3)), padding='same').squeeze()\n",
    "filtered_image_t = F.conv2d(filtered_image_t.reshape((1, 1, 128, 128)), g_right.reshape((1, 1, 3, 3)), padding='same').squeeze()\n",
    "ax.imshow(filtered_image_t.numpy(), cmap='gray', clim=[-300, 450]);  \n",
    "ax.set_title('In three steps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d16de64b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generation of a data set including N samples\n",
    "N = 50\n",
    "x = torch.linspace(0, 4, N, device=gpu)\n",
    "b = 4\n",
    "w = 2\n",
    "noise = torch.normal(torch.zeros(N)).to(gpu)\n",
    "y = (w * x + b + noise).float()\n",
    "\n",
    "# Plot the synthetic data set\n",
    "plt.figure()\n",
    "plt.title(\"Synthetic data\")\n",
    "plt.scatter(x.cpu(), y.cpu(), color='r') # We use this code to map the data back to the CPU\n",
    "plt.xlim(-1, 5)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylim(0, 15)\n",
    "plt.ylabel('$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e01568d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(in_features=1, out_features=1, bias=True, device=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01722a78",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2cae065",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def train(model, iterations, lr, loss_function, x, y):\n",
    "    model.reset_parameters()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    train_loss = []\n",
    "    for iteration in tqdm.tqdm(range(iterations)):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x.unsqueeze(1))\n",
    "        loss = loss_function(output, y.unsqueeze(1))\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ed3e99a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_trained' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_49704/3566162013.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_trained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_trained' is not defined"
     ]
    }
   ],
   "source": [
    "# Using the code below, you can visualize the fitted line. \n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model_trained(x.unsqueeze(1))\n",
    "plt.plot(x.cpu(), output.cpu(), label='prediction')\n",
    "plt.scatter(x.cpu(), y.cpu(), color='r', label='training data')\n",
    "plt.xlim(-1, 5)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylim(0, 15)\n",
    "plt.ylabel('$y$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5adede33",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This block counts the number of parameters in the model.\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8161ef76",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model with bias has 2 parameters\n",
      "The model without bias has 1 parameters\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Linear(in_features=1, out_features=1, bias=True, device=gpu)\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('The model with bias has {} parameters'.format(n_params))\n",
    "\n",
    "model = torch.nn.Linear(in_features=1, out_features=1, bias=False, device=gpu)\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('The model without bias has {} parameters'.format(n_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "515dec59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: monai in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (1.1.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.17 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from monai) (1.21.5)\r\n",
      "Requirement already satisfied: torch>=1.8 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from monai) (1.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from torch>=1.8->monai) (4.4.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: medmnist in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (3.0.1)\r\n",
      "Requirement already satisfied: tqdm in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from medmnist) (4.66.2)\r\n",
      "Requirement already satisfied: torch in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from medmnist) (1.13.1)\r\n",
      "Requirement already satisfied: torchvision in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from medmnist) (0.14.1)\r\n",
      "Requirement already satisfied: pandas in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from medmnist) (1.3.5)\r\n",
      "Requirement already satisfied: fire in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from medmnist) (0.6.0)\r\n",
      "Requirement already satisfied: numpy in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from medmnist) (1.21.5)\r\n",
      "Requirement already satisfied: Pillow in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from medmnist) (9.4.0)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from medmnist) (1.0.2)\r\n",
      "Requirement already satisfied: scikit-image in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from medmnist) (0.19.3)\r\n",
      "Requirement already satisfied: termcolor in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from fire->medmnist) (2.3.0)\r\n",
      "Requirement already satisfied: six in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from fire->medmnist) (1.16.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from pandas->medmnist) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from pandas->medmnist) (2022.7)\r\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image->medmnist) (2.19.3)\r\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image->medmnist) (2.6.3)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image->medmnist) (1.7.3)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image->medmnist) (2021.7.2)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image->medmnist) (1.3.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image->medmnist) (22.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib>=0.11 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-learn->medmnist) (1.1.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-learn->medmnist) (2.2.0)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from torch->medmnist) (4.4.0)\r\n",
      "Requirement already satisfied: requests in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from torchvision->medmnist) (2.28.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from requests->torchvision->medmnist) (2.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from requests->torchvision->medmnist) (2022.12.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from requests->torchvision->medmnist) (1.26.14)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from requests->torchvision->medmnist) (3.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install monai\n",
    "!pip install medmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecbf9235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/jmwolterink/.medmnist/pneumoniamnist.npz\n"
     ]
    }
   ],
   "source": [
    "import medmnist\n",
    "dataset = medmnist.PneumoniaMNIST(split=\"train\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b04ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import monai\n",
    "\n",
    "class MedMNISTData(monai.data.Dataset):\n",
    "    \n",
    "    def __init__(self, datafile, transform=None):\n",
    "        self.data = datafile\n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Make getitem return a dictionary with keys ['img', 'label'] for the image and label respectively\n",
    "        image = self.data[index][0]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return {'img': image, 'label': self.data[index][1]}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "865737a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61084369",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MedMNISTData(dataset, transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc3e98ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGxCAYAAADLfglZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnyklEQVR4nO3df3DU9Z3H8deSH5tfy4YIyWYhxhRRK+F0qhbkVEBrxjjas9Q7aufu4H449gBvGPR65bw7U3tnOnZk+AN/9Do91IqVuxtqvcrUxsOE6wGd4NCRwR+DI0hyEGIgv8lP8r0/aPaM/Py82eSTTZ6PmZ0hm887389+9rN58c3uvjcUBEEgAAA8mOJ7AgCAyYsQAgB4QwgBALwhhAAA3hBCAABvCCEAgDeEEADAG0IIAOANIQQA8IYQwqTwwgsvKBQKac+ePUn5eaFQSKtXr07Kz/rsz6yqqjrvmNraWoVCocTls7ensbFRa9as0aJFi5Sfn69QKKQXXnjhrD/n+uuvT/yMe+65J4m3AnBDCAEp6JlnntGuXbv0xS9+MXHdRx99pM2bNyszM1N33333eet/8pOfaNeuXYrFYqM9VeC80n1PAIC7a6+9VgsWLBhx3W233aZPP/1UkrRnzx799Kc/PWf9vHnzJEnhcHj0JglcBM6EgN/p7e3VI488ouuvv17RaFQFBQW6+eab9fOf//ycNT/84Q911VVXKRwO69prr9Wrr756xpimpiY99NBDmjVrljIzM1VWVqbvfve7GhwcTOr8p0zh4YzUw5kQ8Dt9fX06ceKEHn30Uc2cOVP9/f166623tHTpUm3atEl/+qd/OmL866+/rrfffltPPPGEcnNz9eyzz+qBBx5Qenq67r//fkmnA+jLX/6ypkyZon/8x3/U7NmztWvXLv3TP/2TDh06pE2bNvm4qcC4QQgBvxONRkeEwqlTp3THHXeotbVVGzZsOCOEWlpaVF9fr6KiIknS3XffrfLycq1bty4RQlVVVWptbdX+/ft1+eWXS5LuuOMOZWdn69FHH9Xf/M3f6Nprrx2jWwiMP5y/A5/x7//+7/r93/995eXlKT09XRkZGfrxj3+s999//4yxd9xxRyKAJCktLU3Lli3TRx99pMbGRknSL37xCy1ZskTxeFyDg4OJS2VlpSSprq5ubG4YME4RQsDvbN26VX/0R3+kmTNn6uWXX9auXbtUX1+vP//zP1dvb+8Z48/2yrLh644fPy5JOnbsmP7zP/9TGRkZIy5z586VdPpsCpjM+HMc8Dsvv/yyysrKtGXLFoVCocT1fX19Zx3f1NR0zusuu+wySdL06dP1e7/3e/rnf/7ns/6MeDx+qdMGUhohBPxOKBRSZmbmiABqamo656vj/uu//kvHjh1L/Enu1KlT2rJli2bPnq1Zs2ZJku655x5t27ZNs2fP1rRp00b/RgAphhDCpLJ9+3YdOnTojOvvvvtu3XPPPdq6datWrlyp+++/Xw0NDfre976n4uJiHThw4Iya6dOn6/bbb9c//MM/JF4d98EHH4x4mfYTTzyhmpoaLVy4UH/913+tq6++Wr29vTp06JC2bdum559/PhFYyfAf//EfkqSPP/5Y0un3C+Xl5UlS4sUSwHhCCGFS+du//duzXn/w4EH92Z/9mZqbm/X888/rX//1X/WFL3xB3/nOd9TY2Kjvfve7Z9R89atf1dy5c/X3f//3Onz4sGbPnq3Nmzdr2bJliTHFxcXas2ePvve97+kHP/iBGhsbFYlEVFZWprvuuivpZ0d/+Id/OOLrZ555Rs8884wkKQiCpB4LSIZQwM4EUkZtba2WLFmit956S4sWLVJ6uu3/kadOnVIQBLryyitVXl6uX/ziF0meKXBxeHUckIK+8pWvKCMjw9yQ9YYbblBGRoY++eSTJM8McMOZEJBCOjs79eGHHya+vvbaa5WTk+P8c9577z2dPHlSkpSfn68rr7wyaXMEXBBCAABv+HMcAMAbQggA4A0hBADwZty9T2hoaEhHjhxRJBIZ8c51AEBqCIJAnZ2disfjF/ycq3EXQkeOHFFJSYnvaQAALlFDQ8MFO4KMuxCKRCKSpD/+4z9WZmbmRdfl5+c7Hys3N9e5RpL6+/udazo7O51rhl9C66K5udm55tixY8411mPNnj3bueZs3aov5Oqrr3aukaRrrrnGueaKK65wrpk5c6ZzzbkaqZ6PZd9JtseG5ZNd33vvPeea3/zmN841R44cca6RpA8++MC5Zvfu3aZjubK+UdlSd+rUKafxQRBocHAw8fv8vPNxns1FevbZZ/WDH/xAR48e1dy5c7VhwwbdeuutF6wb/hNcZmamUwiFw2HnOWZlZTnXSDL9mdASXJaPf87IyHCusW5myy8dy7Fc9sEw631rec/NcG82F1OnTnWuOdvHSVyI9R0Ylttk2Q+WsLPct5Y9JNkfG2PB+nSFpW40jzUqL0zYsmWL1qxZo8cee0x79+7VrbfeqsrKSh0+fHg0DgcASFGjEkLr16/XX/zFX+gv//Iv9cUvflEbNmxQSUmJnnvuudE4HAAgRSU9hPr7+/XOO++ooqJixPUVFRXauXPnGeP7+vrU0dEx4gIAmBySHkItLS06depU4oO+hhUVFZ31kyirq6sVjUYTF14ZBwCTx6i9WfXzT0gFQXDWJ6nWrVun9vb2xKWhoWG0pgQAGGeS/tKP6dOnKy0t7Yyznubm5jPOjqTTr2qzvLINAJD6kn4mlJmZqRtuuEE1NTUjrh/+iGMAAIaNyovg165dqz/5kz/RjTfeqJtvvln/8i//osOHD+tb3/rWaBwOAJCiRiWEli1bpuPHj+uJJ57Q0aNHVV5erm3btqm0tHQ0DgcASFGj9nbglStXauXKleb6q6++WtnZ2Rc93vLO67S0NOcaydZOx/JOfMtxLOtQWFjoXCNJ8+fPd66JRqPONZZuE0NDQ841kkxvEWhra3OusewHy3Es6y1J3d3dzjWtra3ONf/7v//rXDMwMOBcY+nmINk6Jli6TYzlHre0f3LtmODSqYOPcgAAeEMIAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN4QQgAAb0atgemlmjp1qlMD08zMTOdjWJsaWuosNS63f9i0adOca6zy8/OdawoKCpxr2tvbnWssTRqtxqrZp6XmyJEjzjWSbe91dXU51/T29jrXWPaQlWXvfelLX3Kuqa+vd66xND0djzgTAgB4QwgBALwhhAAA3hBCAABvCCEAgDeEEADAG0IIAOANIQQA8IYQAgB4QwgBALwhhAAA3hBCAABvCCEAgDfjtov2sWPHlJWVddHjw+Gw8zFycnKcayQpIyPDucbS5dtyHEuNyzp/lqWrs6UDcnFxsXNNT0+Pc41k64htMTg4OCbHsew7ScrNzXWuGRgYcK6xzO/UqVPONVaWx8YVV1zhXHPy5Ennmk8//dS5xnos167qQ0NDamxsvKixnAkBALwhhAAA3hBCAABvCCEAgDeEEADAG0IIAOANIQQA8IYQAgB4QwgBALwhhAAA3hBCAABvCCEAgDfjtoFpW1ubU1NSazNSC8uxXBsASlIkEnGuycvLc66xrp2lkaSlIaSlOa2lkaskTZni/v8yyzpYjhMKhZxr8vPznWskKS0tzbnG0pTVcpssjwvL7ZFsjyfL3istLXWuaWpqcq6RpI6ODuca19vU39+vf/u3f7uosZwJAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN4QQgAAbwghAIA347aBaX9/v1NzQ0uD0CAInGskaWhoyLkmMzPTucbSfHLq1KnONdbmjnPmzDHVuTp69KhzjfU2WZqlWmosjTst+66/v9+5RrI1ZbW47LLLnGuKioqcayyPP0lqbW11rmlra3OusTRltTzWJam7u9u5xnW/9vb2XvRYzoQAAN4QQgAAb5IeQlVVVQqFQiMusVgs2YcBAEwAo/Kc0Ny5c/XWW28lvrb+fR4AMLGNSgilp6dz9gMAuKBReU7owIEDisfjKisr0ze+8Q19/PHH5xzb19enjo6OERcAwOSQ9BCaP3++XnrpJb355pv60Y9+pKamJi1cuFDHjx8/6/jq6mpFo9HEpaSkJNlTAgCMU0kPocrKSn3961/XvHnz9JWvfEVvvPGGJOnFF1886/h169apvb09cWloaEj2lAAA49Sov1k1NzdX8+bN04EDB876/XA4bHqzHwAg9Y36+4T6+vr0/vvvq7i4eLQPBQBIMUkPoUcffVR1dXU6ePCgfvOb3+j+++9XR0eHli9fnuxDAQBSXNL/HNfY2KgHHnhALS0tmjFjhhYsWKDdu3ertLQ02YcCAKS4pIfQq6++mpSfc+LECaemg1lZWc7HsDSRlGxvvrXMLzc317nG4sSJE2NyHOuxjh075lwzY8YM5xpJpj8bT5ni/gcFS01GRoZzTTQada6RpIGBAecaSxPhvr4+55qenh7nGmuzYsvvCMv8LA1Wrfet5XeRa0Nbl+f56R0HAPCGEAIAeEMIAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN6M+ofaWTU3Nys9/eKnl5+f73wMawNTS6PGvLy8MTlOV1eXc42lQagkffLJJ841loaVQ0NDzjXTp093rpFsjSQtXPb2MMsesqyd5N6wUpL6+/udaxobG8ekJhaLOddIUllZmXPNzJkznWtOnjzpXGNtymo5luvvFZcmrpwJAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN4QQgAAbwghAIA3hBAAwJtx20X7xIkTSktLu+jxvb29zsfIyclxrpGkcDjsXFNSUuJc09bW5lzT0tLiXOPS8fazIpGIc42lq7Ol27mlW7dk20eWDu6WDukFBQXONVOm2P6fadlHlv1qYVm71tZW07EsvyNmz57tXGO5b61dtC3d79vb253Gu3Rh50wIAOANIQQA8IYQAgB4QwgBALwhhAAA3hBCAABvCCEAgDeEEADAG0IIAOANIQQA8IYQAgB4QwgBALwZtw1Me3p6nBqYWpr5pafbbv7MmTOda7q6upxrLA0hGxoanGu6u7udayRpYGDAuSYjI8O55rLLLnOuKSwsdK6RpNzcXOcayz6yNGV1aQo5zNrIdXBw0LnG8hi07CFLk1nL7ZFsjU+PHj3qXGNpYGp5LFm57leX8ZwJAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN4QQgAAbwghAIA347aBaWdnp6ZMufiMtDQotDYAtDTU/OSTT5xrmpubnWtaWlqca6zrYGnCOX36dOcaS8PYadOmOddIUjgcdq6xrJ+lZqyankq2+VnWzuUxfiksjVIlW+PhpqYm55rMzEznmvz8fOca67Fc7yeX8ZwJAQC8IYQAAN44h9COHTt07733Kh6PKxQK6bXXXhvx/SAIVFVVpXg8ruzsbC1evFj79+9P1nwBABOIcwh1d3fruuuu08aNG8/6/aeeekrr16/Xxo0bVV9fr1gspjvvvFOdnZ2XPFkAwMTi/MKEyspKVVZWnvV7QRBow4YNeuyxx7R06VJJ0osvvqiioiK98soreuihhy5ttgCACSWpzwkdPHhQTU1NqqioSFwXDoe1aNEi7dy586w1fX196ujoGHEBAEwOSQ2h4ZcmFhUVjbi+qKjonC9brK6uVjQaTVxKSkqSOSUAwDg2Kq+O+/z7GYIgOOd7HNatW6f29vbEpaGhYTSmBAAYh5L6ZtVYLCbp9BlRcXFx4vrm5uYzzo6GhcNh05vcAACpL6lnQmVlZYrFYqqpqUlc19/fr7q6Oi1cuDCZhwIATADOZ0JdXV366KOPEl8fPHhQv/3tb1VQUKDLL79ca9as0ZNPPqk5c+Zozpw5evLJJ5WTk6NvfvObSZ04ACD1OYfQnj17tGTJksTXa9eulSQtX75cL7zwgr797W+rp6dHK1euVGtrq+bPn69f/epXikQiyZs1AGBCcA6hxYsXKwiCc34/FAqpqqpKVVVVlzIvDQwMODXBy8rKcj6GpZmmdPpPjK7a29uda7q7u51rcnNznWusDUwtdZY1tzRqtDbGtDT8TEtLc66xNJE83+Mu2Sz3reUxaHk+2LLeVr29vc41lkazPT09zjWWRsqS7X5yvU0u4+kdBwDwhhACAHhDCAEAvCGEAADeEEIAAG8IIQCAN4QQAMAbQggA4A0hBADwhhACAHhDCAEAvCGEAADeEEIAAG+S+smqyZSWlubUCXnGjBnOx4jH4841ktTS0uJc09fX51xj6aJt6X5s6RQsSXl5ec41lg7Ils7WQ0NDzjXS2HXETk93f+hZ9pC18/bg4KCpzpVlv1ruI+t+sHTMt3Rwb2trc6757KdXu7DMz3UfuYznTAgA4A0hBADwhhACAHhDCAEAvCGEAADeEEIAAG8IIQCAN4QQAMAbQggA4A0hBADwhhACAHhDCAEAvBm3DUzT09OdGu3l5+c7H8PSyE+SGhsbnWsszUhbW1udayzNPk+ePOlcI0lTp051rrGsQ1ZWlnNNTk6Oc40kZWdnO9eEw2HnmlAo5FxjacJpafYp2faRpRlpNBodk5quri7nGsnWyNXSnNbSwHRgYMC5xsq1kavLeM6EAADeEEIAAG8IIQCAN4QQAMAbQggA4A0hBADwhhACAHhDCAEAvCGEAADeEEIAAG8IIQCAN4QQAMCbcdvAND8/36n54rRp05yP0dLS4lwjje9mg5a55ebmmo5lafZpbajpytJEUrI1Ix3Pt8nSgFOyNUsdzw1Mm5qanGsk98adVpYmwtb71tK42fVYLuM5EwIAeEMIAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN4QQgAAb8ZtA9NYLObUsLGgoMD5GO3t7c41khQKhUx1riy3qbu727nmyiuvdK6RpBkzZjjXWJpwWhpjWmqsgiBwrrGsg6VhbFdXl3ONZGvcaWnkarmfLGtnbSBsaSyamZnpXGO5TdYmvZbfX6dOnRq18ZwJAQC8IYQAAN44h9COHTt07733Kh6PKxQK6bXXXhvx/RUrVigUCo24LFiwIFnzBQBMIM4h1N3dreuuu04bN24855i77rpLR48eTVy2bdt2SZMEAExMzs9sVVZWqrKy8rxjwuGwYrGYeVIAgMlhVJ4Tqq2tVWFhoa666io9+OCDam5uPufYvr4+dXR0jLgAACaHpIdQZWWlNm/erO3bt+vpp59WfX29br/9dvX19Z11fHV1taLRaOJSUlKS7CkBAMappL9PaNmyZYl/l5eX68Ybb1RpaaneeOMNLV269Izx69at09q1axNfd3R0EEQAMEmM+ptVi4uLVVpaqgMHDpz1++FwWOFweLSnAQAYh0b9fULHjx9XQ0ODiouLR/tQAIAU43wm1NXVpY8++ijx9cGDB/Xb3/5WBQUFKigoUFVVlb7+9a+ruLhYhw4d0t/93d9p+vTp+trXvpbUiQMAUp9zCO3Zs0dLlixJfD38fM7y5cv13HPPad++fXrppZfU1tam4uJiLVmyRFu2bFEkEknerAEAE4JzCC1evPi8DRvffPPNS5rQsJKSEqdGgLm5uc7H2L9/v3ONZGtqePz4cecaSzPS/Px855pzvXLxQlybGkoy/Vl2cHDQuWbKFNtfmi0NNYeGhsakxtKMNCcnx7lGsjW5tNwmS6PUrKws55rZs2c710hSU1OTc82RI0ecaywvxvrggw+cayTp+uuvd67p6elxGt/b23vRY+kdBwDwhhACAHhDCAEAvCGEAADeEEIAAG8IIQCAN4QQAMAbQggA4A0hBADwhhACAHhDCAEAvCGEAADeEEIAAG9G/ZNVrSKRiNMnrg4MDDgfw9o9+nxdxM8lOzvbucbSpTo93f0utXQ/lmzrZ7mfLCzrINm6aFuOZfk0Ycv9ZOn4LtnuW8vjwsLSGdz6UTKu3aMlqb293bnGcj9ZuolLtsega43LeM6EAADeEEIAAG8IIQCAN4QQAMAbQggA4A0hBADwhhACAHhDCAEAvCGEAADeEEIAAG8IIQCAN4QQAMCbcdvANB6POzXoszRc7OjocK6RpP7+fueatLQ05xpLQ0jLOlibXA4ODjrXWJpwWtZuypSx+/+VpdGspYmk5ThWlvvJsh8s921mZqZzzdSpU51rJNtjIy8vz7mms7PTucay3pJtH7n+XnH5HcmZEADAG0IIAOANIQQA8IYQAgB4QwgBALwhhAAA3hBCAABvCCEAgDeEEADAG0IIAOANIQQA8IYQAgB4M24bmObn5ys7O/uix7e1tTkfo6WlxblGknp6epxrLA0ULc1ILTVWra2tzjXTpk1zrsnJyXGuiUQizjVWY9Xs09qwcqxYGu5ammmOZSPXcDjsXGNpYHrixAnnGut+GIvGwy7jORMCAHhDCAEAvCGEAADeEEIAAG8IIQCAN4QQAMAbQggA4A0hBADwhhACAHhDCAEAvCGEAADeEEIAAG/GbQPT3t5ehUKhix7f1dXlfAyXn/9ZWVlZzjWWxp39/f3ONZbbZGnSKNmaxlpqLI0xCwoKnGskKT3d/SExZYr7/+UyMjLGpMbSZNbKsvcszV8tjwtr09PMzEznmmg06lxjWYfe3l7nGmuda9NTl/GcCQEAvCGEAADeOIVQdXW1brrpJkUiERUWFuq+++7Thx9+OGJMEASqqqpSPB5Xdna2Fi9erP379yd10gCAicEphOrq6rRq1Srt3r1bNTU1GhwcVEVFhbq7uxNjnnrqKa1fv14bN25UfX29YrGY7rzzTnV2diZ98gCA1Ob0LOwvf/nLEV9v2rRJhYWFeuedd3TbbbcpCAJt2LBBjz32mJYuXSpJevHFF1VUVKRXXnlFDz30UPJmDgBIeZf0nFB7e7uk/38l0sGDB9XU1KSKiorEmHA4rEWLFmnnzp1n/Rl9fX3q6OgYcQEATA7mEAqCQGvXrtUtt9yi8vJySVJTU5MkqaioaMTYoqKixPc+r7q6WtFoNHEpKSmxTgkAkGLMIbR69Wq9++67+ulPf3rG9z7/foEgCM75HoJ169apvb09cWloaLBOCQCQYkxvVn344Yf1+uuva8eOHZo1a1bi+lgsJun0GVFxcXHi+ubm5jPOjoaFw2HzmyUBAKnN6UwoCAKtXr1aW7du1fbt21VWVjbi+2VlZYrFYqqpqUlc19/fr7q6Oi1cuDA5MwYATBhOZ0KrVq3SK6+8op///OeKRCKJ53mi0aiys7MVCoW0Zs0aPfnkk5ozZ47mzJmjJ598Ujk5OfrmN785KjcAAJC6nELoueeekyQtXrx4xPWbNm3SihUrJEnf/va31dPTo5UrV6q1tVXz58/Xr371K0UikaRMGAAwcTiF0MU0kgyFQqqqqlJVVZV1TpJO/xkvLS3tosdbGk8Ov6rPleVYllf9jVUDU0vzROn/X6LvwtLc0dJE0nIfSXLac6mgr6/PVOfasFKy7SNLc1pLjZWlOa1l71nWztIMWLI9bl0bwLqMp3ccAMAbQggA4A0hBADwhhACAHhDCAEAvCGEAADeEEIAAG8IIQCAN4QQAMAbQggA4A0hBADwhhACAHhDCAEAvLG1Gh4DeXl5ys7OvujxLmOHWTpbS7aOt/F43LnG0snY0sHXtUPusO7ubueanJwc55rOzk7nGkv3Y8m25pb1GxgYcK6xzM3Sid1aN1b71dJF2zI3STp58qRzTWtrq3ON5TZZHn+S7fHk2p3fZTxnQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgzbhtYJqbm+vU7DIvL8/5GIWFhc41ktTV1eVcY2momZaW5lxjaeRqZVlzyzr09vY611iazEq2ZqSWY1nWwVJjXQdLA1PL2lkad1puU19fn3ONJLW3tzvXHDt2zLnGtUGoZL9NljrXvecynjMhAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPBm3DYwzcvLU25u7kWPz8/Pdz6GpeGiJE2bNs25xtKM1KWB6zBLI0Rrk0sLy7FmzJjhXJORkeFccyl1rgYHB8ekxtKAU5LC4bBzTVZWlnONZb0teygajTrXSLbfK7NmzXKu+Z//+R/nmk8//dS5RpLee+8955ovfOELTuNdmg5zJgQA8IYQAgB4QwgBALwhhAAA3hBCAABvCCEAgDeEEADAG0IIAOANIQQA8IYQAgB4QwgBALwhhAAA3ozbBqbhcNipiWJ6uvtNmTLFlsGWJqGWY1lqLI1SrSzzszSfHMt1sDTUtOyH/v5+5xrLHo/H48410tjtcct+sDQeDoLAuUYauwar11xzjXONpcmsJA0MDDjXuK6fy3jOhAAA3hBCAABvnEKourpaN910kyKRiAoLC3Xffffpww8/HDFmxYoVCoVCIy4LFixI6qQBABODUwjV1dVp1apV2r17t2pqajQ4OKiKigp1d3ePGHfXXXfp6NGjicu2bduSOmkAwMTg9EznL3/5yxFfb9q0SYWFhXrnnXd02223Ja4Ph8OKxWLJmSEAYMK6pOeEhj86uKCgYMT1tbW1Kiws1FVXXaUHH3xQzc3N5/wZfX196ujoGHEBAEwO5hAKgkBr167VLbfcovLy8sT1lZWV2rx5s7Zv366nn35a9fX1uv3229XX13fWn1NdXa1oNJq4lJSUWKcEAEgx5vcJrV69Wu+++65+/etfj7h+2bJliX+Xl5frxhtvVGlpqd544w0tXbr0jJ+zbt06rV27NvF1R0cHQQQAk4QphB5++GG9/vrr2rFjh2bNmnXescXFxSotLdWBAwfO+n3XN6UCACYOpxAKgkAPP/ywfvazn6m2tlZlZWUXrDl+/LgaGhpUXFxsniQAYGJyek5o1apVevnll/XKK68oEomoqalJTU1N6unpkSR1dXXp0Ucf1a5du3To0CHV1tbq3nvv1fTp0/W1r31tVG4AACB1OZ0JPffcc5KkxYsXj7h+06ZNWrFihdLS0rRv3z699NJLamtrU3FxsZYsWaItW7YoEokkbdIAgInB+c9x55Odna0333zzkiYEAJg8xm0X7fT0dKeuwZZut9ZOy2PV1XmsbtNYdhO3dDO2HMfScdpaN1Ydpy3dj2fMmOFcI0mDg4NjUmPpJm45jqXztmTrVG3ZD1dccYVzTWZmpnONJLW1tTnX9Pb2Oo136SROA1MAgDeEEADAG0IIAOANIQQA8IYQAgB4QwgBALwhhAAA3hBCAABvCCEAgDeEEADAG0IIAOANIQQA8GbcNjB1NZZNLi2NRceqGam1KauFpQmnS2NDXDrL48LK0pzWwrLvxrKhraVZqqVm2rRpzjWSbU+0trY6jXfZC5wJAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8IYQAAN4QQgAAb8Zd77jhnkPd3d1OdZaeaZYeVJLU39/vXGPpQZWZmelcQ++408ayV5ilF9fg4KBzzcDAwJgcZyyPZTmOZQ9ZHrOS1NfXNyY1lt5xPT09zjWSdPLkyVE/1vD4i+khFwrGquvgRWpsbFRJSYnvaQAALlFDQ4NmzZp13jHjLoSGhoZ05MgRRSKRM/6H2dHRoZKSEjU0NGjq1KmeZugf63Aa63Aa63Aa63DaeFiHIAjU2dmpeDx+wb+YjLs/x02ZMuWCyTl16tRJvcmGsQ6nsQ6nsQ6nsQ6n+V6HaDR6UeN4YQIAwBtCCADgTUqFUDgc1uOPP65wOOx7Kl6xDqexDqexDqexDqel2jqMuxcmAAAmj5Q6EwIATCyEEADAG0IIAOANIQQA8IYQAgB4k1Ih9Oyzz6qsrExZWVm64YYb9N///d++pzSmqqqqFAqFRlxisZjvaY26HTt26N5771U8HlcoFNJrr7024vtBEKiqqkrxeFzZ2dlavHix9u/f72eyo+hC67BixYoz9seCBQv8THaUVFdX66abblIkElFhYaHuu+8+ffjhhyPGTIb9cDHrkCr7IWVCaMuWLVqzZo0ee+wx7d27V7feeqsqKyt1+PBh31MbU3PnztXRo0cTl3379vme0qjr7u7Wddddp40bN571+0899ZTWr1+vjRs3qr6+XrFYTHfeeac6OzvHeKaj60LrIEl33XXXiP2xbdu2MZzh6Kurq9OqVau0e/du1dTUaHBwUBUVFSO67k+G/XAx6yClyH4IUsSXv/zl4Fvf+taI66655prgO9/5jqcZjb3HH388uO6663xPwytJwc9+9rPE10NDQ0EsFgu+//3vJ67r7e0NotFo8Pzzz3uY4dj4/DoEQRAsX748+IM/+AMv8/Glubk5kBTU1dUFQTB598Pn1yEIUmc/pMSZUH9/v9555x1VVFSMuL6iokI7d+70NCs/Dhw4oHg8rrKyMn3jG9/Qxx9/7HtKXh08eFBNTU0j9kY4HNaiRYsm3d6QpNraWhUWFuqqq67Sgw8+qObmZt9TGlXt7e2SpIKCAkmTdz98fh2GpcJ+SIkQamlp0alTp1RUVDTi+qKiIjU1NXma1dibP3++XnrpJb355pv60Y9+pKamJi1cuFDHjx/3PTVvhu//yb43JKmyslKbN2/W9u3b9fTTT6u+vl6333676UPWUkEQBFq7dq1uueUWlZeXS5qc++Fs6yClzn4Ydx/lcD6f/3yhIAhMn2qZqiorKxP/njdvnm6++WbNnj1bL774otauXetxZv5N9r0hScuWLUv8u7y8XDfeeKNKS0v1xhtvaOnSpR5nNjpWr16td999V7/+9a/P+N5k2g/nWodU2Q8pcSY0ffp0paWlnfE/mebm5jP+xzOZ5Obmat68eTpw4IDvqXgz/OpA9saZiouLVVpaOiH3x8MPP6zXX39db7/99ojPH5ts++Fc63A243U/pEQIZWZm6oYbblBNTc2I62tqarRw4UJPs/Kvr69P77//voqLi31PxZuysjLFYrERe6O/v191dXWTem9I0vHjx9XQ0DCh9kcQBFq9erW2bt2q7du3q6ysbMT3J8t+uNA6nM243Q8eXxTh5NVXXw0yMjKCH//4x8F7770XrFmzJsjNzQ0OHTrke2pj5pFHHglqa2uDjz/+ONi9e3dwzz33BJFIZMKvQWdnZ7B3795g7969gaRg/fr1wd69e4NPPvkkCIIg+P73vx9Eo9Fg69atwb59+4IHHnggKC4uDjo6OjzPPLnOtw6dnZ3BI488EuzcuTM4ePBg8Pbbbwc333xzMHPmzAm1Dn/1V38VRKPRoLa2Njh69GjicvLkycSYybAfLrQOqbQfUiaEgiAInnnmmaC0tDTIzMwMvvSlL414OeJksGzZsqC4uDjIyMgI4vF4sHTp0mD//v2+pzXq3n777UDSGZfly5cHQXD6ZbmPP/54EIvFgnA4HNx2223Bvn37/E56FJxvHU6ePBlUVFQEM2bMCDIyMoLLL788WL58eXD48GHf006qs91+ScGmTZsSYybDfrjQOqTSfuDzhAAA3qTEc0IAgImJEAIAeEMIAQC8IYQAAN4QQgAAbwghAIA3hBAAwBtCCADgDSEEAPCGEAIAeEMIAQC8+T/7hc0e8/suZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_dataset[0]['img'].squeeze(), cmap='gray')\n",
    "plt.title('Label {}'.format(train_dataset[0]['label']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c90313bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = monai.data.DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20872b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.fc1 = nn.Linear(in_features=9216, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        output = self.fc2(x)\n",
    "        return output\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58da3628",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1198721"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in net.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ee37673",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Net().to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df58d186",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4) \n",
    "loss_function = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60fe1c04",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_medmnist(model, train_dataloader, val_dataloader, optimizer, epochs, device=gpu, val_freq=1):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        steps = 0\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            images = batch['img'].float().to(device)\n",
    "            labels = batch['label'].float().to(device)\n",
    "            output = model(images) \n",
    "            loss = loss_function(output, labels)\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            steps += 1\n",
    "           \n",
    "        train_loss.append(epoch_loss/steps)\n",
    "\n",
    "        # validation loop\n",
    "        if epoch % val_freq == 0:\n",
    "            steps = 0\n",
    "            val_epoch_loss = 0\n",
    "            model.eval()\n",
    "            for batch in val_dataloader:\n",
    "                images = batch['img'].float().to(device)\n",
    "                labels = batch['label'].float().to(device)\n",
    "                output = model(images) \n",
    "                loss = loss_function(output, labels)\n",
    "                val_epoch_loss += loss.item()\n",
    "                steps += 1\n",
    "            val_loss.append(val_epoch_loss/steps)\n",
    "\n",
    "    return train_loss, val_loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98e2ed0e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_49704/4140317621.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mval_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_medmnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "val_freq = 10\n",
    "n_epochs = 100\n",
    "train_loss, val_loss, model = train_medmnist(model, train_dataloader, val_dataloader, optimizer, epochs=n_epochs, val_freq=val_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82fec116",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a8ad432",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def validation_results_ROC(model, dataloader):\n",
    "    for data in dataloader:\n",
    "        images = data['img'].float().to(gpu)\n",
    "        labels = data['label']\n",
    "        with torch.no_grad():\n",
    "            output = model(images).cpu()\n",
    "        fpr, tpr, _ = roc_curve(labels, output.squeeze(1))\n",
    "        print(auc(fpr, tpr))\n",
    "        plt.plot(fpr,tpr)\n",
    "        plt.xlabel('False positive rate')\n",
    "        plt.ylabel('False negative rate')\n",
    "        plt.plot([0,1], [0,1], 'r--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f8f8cdb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def validation_results_visualize(model, dataset):\n",
    "    index = np.random.randint(0, len(dataset))\n",
    "    image = dataset[index]['img']\n",
    "    plt.imshow(image.numpy().squeeze(), cmap='gray')\n",
    "    image = image.float().to(gpu)\n",
    "    label = dataset[index]['label'].item()\n",
    "    with torch.no_grad():\n",
    "        output = F.sigmoid(model(image.unsqueeze(0)))\n",
    "    plt.title(f'Ground truth: {label}, prediction: {int(output)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "394209b6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_49704/1104208159.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidation_results_visualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "validation_results_visualize(model, val_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}