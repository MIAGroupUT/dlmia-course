{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ead260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚å®Ô∏è add path:\n",
    "data_path = \"../data/Tutorial_3/ribs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe596ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please update your data path to an existing folder.\n"
     ]
    }
   ],
   "source": [
    "# check if data_path exists:\n",
    "import os\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    print(\"Please update your data path to an existing folder.\")\n",
    "elif not set([\"train\", \"val\", \"test\"]).issubset(set(os.listdir(data_path))):\n",
    "    print(\"Please update your data path to the correct folder (should contain train, val and test folders).\")\n",
    "else:\n",
    "    print(\"Congrats! You selected the correct folder :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b59fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (0.19.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image) (1.3.0)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image) (1.7.3)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image) (2021.7.2)\r\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image) (1.21.5)\r\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image) (2.19.3)\r\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image) (9.4.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image) (22.0)\r\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from scikit-image) (2.6.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (0.16.6)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (65.6.3)\r\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (3.1.43)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (1.45.0)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (4.4.0)\r\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (8.0.4)\r\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (1.4.4)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (4.24.4)\r\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (2.28.1)\r\n",
      "Requirement already satisfied: setproctitle in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (1.3.3)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (5.9.0)\r\n",
      "Requirement already satisfied: PyYAML in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from wandb) (6.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from Click!=8.0.0,>=7.1->wandb) (4.11.3)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from importlib-metadata->Click!=8.0.0,>=7.1->wandb) (3.11.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: monai in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (1.1.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.17 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from monai) (1.21.5)\r\n",
      "Requirement already satisfied: torch>=1.8 in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from monai) (1.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages (from torch>=1.8->monai) (4.4.0)\r\n"
     ]
    }
   ],
   "source": [
    "# Install additional packages required for this tutorial\n",
    "!pip install scikit-image\n",
    "!pip install wandb\n",
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fe3719e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjelmerwolterink\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d6d34c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/jmwolterink/Library/CloudStorage/OneDrive-UniversityofTwente/Teaching/DLMIA_2023_2024/dlmia-course/notebooks/Tutorial3_Segmentation/wandb/run-20240515_100649-jqv58hq7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mExample run\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/jelmerwolterink/Example%20project\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/jelmerwolterink/Example%20project/runs/jqv58hq7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project='Example project', name='Example run', config={'dataset': 'VinDr-RibCXR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb2bd41",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.015 MB of 0.015 MB uploaded\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Accuracy ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñá‚ñÑ‚ñÑ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÇ‚ñÜ‚ñÇ‚ñÜ‚ñÖ‚ñÉ‚ñà‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñà‚ñÅ‚ñà‚ñà‚ñÉ‚ñÖ‚ñÉ‚ñà‚ñÉ‚ñÑ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     Loss ‚ñÜ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñá‚ñá‚ñÑ‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÜ‚ñÉ‚ñÜ‚ñà‚ñÇ‚ñÇ‚ñá‚ñá‚ñÇ‚ñá‚ñá‚ñà‚ñÜ‚ñÉ‚ñá‚ñÉ‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñà‚ñÇ‚ñÜ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Accuracy 0.38454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     Loss 0.7066\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mExample run\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/jelmerwolterink/Example%20project/runs/jqv58hq7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/jelmerwolterink/Example%20project\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240515_100649-jqv58hq7/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# time.sleep(1) makes the script wait for 1 second, so the full script takes about 60 seconds to finish\n",
    "for step in range(60):\n",
    "    wandb.log({'Loss': random.random(), 'Accuracy': random.random()})\n",
    "    time.sleep(1)\n",
    "    \n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd227d28",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import monai\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "def build_dict_ribs(data_path, mode='train'):\n",
    "    \"\"\"\n",
    "    This function returns a list of dictionaries, each dictionary containing the keys 'img' and 'mask' \n",
    "    that returns the path to the corresponding image.\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): path to the root folder of the data set.\n",
    "        mode (str): subset used. Must correspond to 'train', 'val' or 'test'.\n",
    "        \n",
    "    Returns:\n",
    "        (List[Dict[str, str]]) list of the dictionaries containing the paths of X-ray images and masks.\n",
    "    \"\"\"\n",
    "    # test if mode is correct\n",
    "    if mode not in [\"train\", \"val\", \"test\"]:\n",
    "        raise ValueError(f\"Please choose a mode in ['train', 'val', 'test']. Current mode is {mode}.\")\n",
    "    \n",
    "    # define empty dictionary\n",
    "    dicts = []\n",
    "    # list all .png files in directory, including the path\n",
    "    paths_xray = glob.glob(os.path.join(data_path, mode, 'img', '*.png'))\n",
    "    # make a corresponding list for all the mask files\n",
    "    for xray_path in paths_xray:\n",
    "        if mode == 'test':\n",
    "            suffix = 'val'\n",
    "        else:\n",
    "            suffix = mode\n",
    "        # find the binary mask that belongs to the original image, based on indexing in the filename\n",
    "        image_index = os.path.split(xray_path)[1].split('_')[-1].split('.')[0]\n",
    "        # define path to mask file based on this index and add to list of mask paths\n",
    "        mask_path = os.path.join(data_path, mode, 'mask', f'VinDr_RibCXR_{suffix}_{image_index}.png')\n",
    "        if os.path.exists(mask_path):\n",
    "            dicts.append({'img': xray_path, 'mask': mask_path})\n",
    "    return dicts\n",
    "\n",
    "class LoadRibData(monai.transforms.Transform):\n",
    "    \"\"\"\n",
    "    This custom Monai transform loads the data from the rib segmentation dataset.\n",
    "    Defining a custom transform is simple; just overwrite the __init__ function and __call__ function.\n",
    "    \"\"\"\n",
    "    def __init__(self, keys=None):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = Image.open(sample['img']).convert('L') # import as grayscale image\n",
    "        image = np.array(image, dtype=np.uint8)\n",
    "        mask = Image.open(sample['mask']).convert('L') # import as grayscale image\n",
    "        mask = np.array(mask, dtype=np.uint8)\n",
    "        # mask has value 255 on rib pixels. Convert to binary array\n",
    "        mask[np.where(mask==255)] = 1\n",
    "        return {'img': image, 'mask': mask, 'img_meta_dict': {'affine': np.eye(2)}, \n",
    "                'mask_meta_dict': {'affine': np.eye(2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a798e021",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# construct list of dictionaries\n",
    "train_dict_list = build_dict_ribs(data_path, mode='train')\n",
    "# construct CacheDataset from list of paths + transform\n",
    "train_dataset = monai.data.CacheDataset(train_dict_list, transform=LoadRibData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3da36f9a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# ‚å®Ô∏è print the length of each subset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97b8c5af",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# ‚å®Ô∏è print the dimensions of a bunch of images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28630d4e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ecb49ec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_rib_sample(sample, title=None):\n",
    "    # Visualize the x-ray and overlay the mask, using the dictionary as input\n",
    "    image = np.squeeze(sample['img'])\n",
    "    mask = np.squeeze(sample['mask'])\n",
    "    plt.figure(figsize=[10,7])\n",
    "    plt.imshow(image, 'gray')\n",
    "    overlay_mask = np.ma.masked_where(mask == 0, mask == 1)\n",
    "    plt.imshow(overlay_mask, 'Greens', alpha = 0.7, clim=[0,1], interpolation='nearest')\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7ffed5f",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# ‚å®Ô∏è visualize samples here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f744489",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_49750/1625175677.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This picks a random sample, but you can change this value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msample_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvisualize_rib_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Original sample\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "# Load sample\n",
    "index = np.random.choice(np.arange(len(train_dataset))) # This picks a random sample, but you can change this value\n",
    "sample_dict = train_dataset[index]\n",
    "visualize_rib_sample(sample_dict, title=\"Original sample\")\n",
    "\n",
    "# Add channels\n",
    "add_channels_transform = monai.transforms.AddChanneld(keys=['img', 'mask']) # Initialize the transform\n",
    "channels_sample_dict = add_channels_transform(sample_dict) # Apply the transform\n",
    "print(\"Size of the image before AddChanneld transform\", sample_dict[\"img\"].shape)\n",
    "print(\"Size of the image after AddChanneld transform\", channels_sample_dict[\"img\"].shape)\n",
    "\n",
    "# Random flip\n",
    "# here we define the keys, the probability that the flip is performed and the axis to flip over\n",
    "random_flip_transform = monai.transforms.RandFlipd(keys=['img', 'mask'], prob=1, spatial_axis=1)\n",
    "# We put a probability of 1 to always flip the image for visualization purposes.\n",
    "# Please DO NOT DO THAT in the rest of the notebook.\n",
    "flipped_sample_dict = random_flip_transform(channels_sample_dict)\n",
    "visualize_rib_sample(flipped_sample_dict, title=\"(Not quite randomly) flipped sample\")\n",
    "\n",
    "# Random rotation\n",
    "# Here we define the keys in the dictionary that contain the data, the rotation range, but also the interpolation mode. \n",
    "# The interpolation mode defines how new pixel values for the rotated image are computed. \n",
    "# Note that these differ between mask and image, as we want to keep binary labels for the masks, and (bi)linear interpolation\n",
    "# would result in scalar values between 0 and 1.\n",
    "random_rotation_transform = monai.transforms.RandRotated(keys=['img', 'mask'], range_x=np.pi/4, prob=1, mode=['bilinear', 'nearest'])\n",
    "rotated_sample_dict = random_rotation_transform(channels_sample_dict)\n",
    "visualize_rib_sample(rotated_sample_dict, title=\"Randomly rotated sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c3b18a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_49750/330516906.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create the composed transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Apply this new single transform to sample_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# dataset[[1, 3, 4]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# if existing in cache, try to get the index in cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0mcache_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hash_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_num\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# support negative index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m             \u001b[0mcache_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "sample_dict = train_dataset[0]\n",
    "\n",
    "# Create the composed transform\n",
    "\n",
    "# Apply this new single transform to sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bccd2b02",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# ‚å®Ô∏è code your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73fb7954",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# ‚å®Ô∏è code your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f100236",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# ‚å®Ô∏è code your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b9f85c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The used device is cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'The used device is {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90e52d0d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = monai.networks.nets.UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(8, 16, 32, 64, 128),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bf23de6",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# ‚å®Ô∏è code your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "310d28c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_function =  monai.losses.DiceLoss(sigmoid=True, batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57382e20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4055c65",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'from_compose_to_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_49750/3802791442.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;34m'loss function'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;34m'transform'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfrom_compose_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'from_compose_to_list' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "run = wandb.init(\n",
    "    project='tutorial3_segmentation',\n",
    "    name='test',\n",
    "    config={\n",
    "        'loss function': str(loss_function), \n",
    "        'lr': optimizer.param_groups[0][\"lr\"],\n",
    "        'transform': from_compose_to_list(train_transform),\n",
    "        'batch_size': train_loader.batch_size,\n",
    "    }\n",
    ")\n",
    "# Do not hesitate to enrich this list of settings to be able to correctly keep track of your experiments!\n",
    "# For example you should add information on your model...\n",
    "\n",
    "run_id = run.id # We remember here the run ID to be able to write the evaluation metrics\n",
    "\n",
    "def wandb_masks(mask_output, mask_gt):\n",
    "    \"\"\" Function that generates a mask dictionary in format that W&B requires \"\"\"\n",
    "\n",
    "    # Apply sigmoid to model ouput and round to nearest integer (0 or 1)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    mask_output = sigmoid(mask_output)\n",
    "    mask_output = torch.round(mask_output)\n",
    "\n",
    "    # Transform masks to numpy arrays on CPU\n",
    "    # Note: .squeeze() removes all dimensions with a size of 1 (here, it makes the tensors 2-dimensional)\n",
    "    # Note: .detach() removes a tensor from the computational graph to prevent gradient computation for it\n",
    "    mask_output = mask_output.squeeze().detach().cpu().numpy()\n",
    "    mask_gt = mask_gt.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    # Create mask dictionary with class label and insert masks\n",
    "    class_labels = {1: 'ribs'}\n",
    "    masks = {\n",
    "        'predictions': {'mask_data': mask_output, 'class_labels': class_labels},\n",
    "        'ground truth': {'mask_data': mask_gt, 'class_labels': class_labels}\n",
    "    }\n",
    "    return masks\n",
    "\n",
    "def log_to_wandb(epoch, train_loss, val_loss, batch_data, outputs):\n",
    "    \"\"\" Function that logs ongoing training variables to W&B \"\"\"\n",
    "\n",
    "    # Create list of images that have segmentation masks for model output and ground truth\n",
    "    log_imgs = [wandb.Image(img, masks=wandb_masks(mask_output, mask_gt)) for img, mask_output,\n",
    "                mask_gt in zip(batch_data['img'], outputs, batch_data['mask'])]\n",
    "\n",
    "    # Send epoch, losses and images to W&B\n",
    "    wandb.log({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss, 'results': log_imgs})\n",
    "    \n",
    "# ‚å®Ô∏è WRITE YOUR TRAINING LOOP HERE\n",
    "\n",
    "# Store the network parameters        \n",
    "torch.save(model.state_dict(), r'trainedUNet.pt')\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5793f627",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def visual_evaluation(sample, model):\n",
    "    \"\"\"\n",
    "    Allow the visual inspection of one sample by plotting the X-ray image, the ground truth (green)\n",
    "    and the segmentation map produced by the network (red).\n",
    "    \n",
    "    Args:\n",
    "        sample (Dict[str, torch.Tensor]): sample composed of an X-ray ('img') and a mask ('mask').\n",
    "        model (torch.nn.Module): trained model to evaluate.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    inferer = monai.inferers.SlidingWindowInferer(roi_size=[256, 256])\n",
    "    discrete_transform = monai.transforms.AsDiscrete(logit_thresh=0.5, threshold_values=True)\n",
    "    Sigmoid = torch.nn.Sigmoid()\n",
    "    with torch.no_grad():\n",
    "        output = discrete_transform(Sigmoid(inferer(sample['img'].to(device), network=model).cpu())).squeeze()\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3, figsize = [12, 10])\n",
    "    # Plot X-ray image\n",
    "    ax[0].imshow(sample[\"img\"].squeeze(), 'gray')    \n",
    "    ax[1].imshow(sample[\"img\"].squeeze(), 'gray')\n",
    "    # Plot ground truth\n",
    "    mask = np.squeeze(sample['mask'])\n",
    "    overlay_mask = np.ma.masked_where(mask == 0, mask == 1)\n",
    "    ax[1].imshow(overlay_mask, 'Greens', alpha = 0.7, clim=[0,1], interpolation='nearest')\n",
    "    ax[1].set_title('Ground truth')\n",
    "    # Plot output\n",
    "    overlay_output = np.ma.masked_where(output < 0.1, output >0.99)\n",
    "    ax[2].imshow(sample['img'].squeeze(), 'gray')\n",
    "    ax[2].imshow(overlay_output, 'Reds', alpha = 0.7, clim=[0,1])\n",
    "    ax[2].set_title('Prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4e11000",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmwolterink/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/utils/deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "  warn_deprecated(obj, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "test_dict = build_dict_ribs(data_path, mode='test')\n",
    "test_transform = monai.transforms.Compose([\n",
    "        LoadRibData(),\n",
    "        monai.transforms.AddChanneld(keys=['img', 'mask']),\n",
    "        monai.transforms.ScaleIntensityd(keys=['img'],minv=0, maxv=1),\n",
    "        monai.transforms.Zoomd(keys=['img', 'mask'], zoom=0.25, keep_size=False, mode=['bilinear', 'nearest']),\n",
    "    ]\n",
    ")\n",
    "test_set = monai.data.CacheDataset(test_dict, transform=test_transform)\n",
    "test_loader = monai.data.DataLoader(test_set, batch_size=1)\n",
    "\n",
    "for sample in test_loader:\n",
    "    visual_evaluation(sample, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f1a95d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric(dataloader, model, metric_fn):\n",
    "    \"\"\"\n",
    "    This function computes the average value of a metric for a data set.\n",
    "    \n",
    "    Args:\n",
    "        dataloader (monai.data.DataLoader): dataloader wrapping the dataset to evaluate.\n",
    "        model (torch.nn.Module): trained model to evaluate.\n",
    "        metric_fn (function): function computing the metric value from two tensors:\n",
    "            - a batch of outputs,\n",
    "            - the corresponding batch of ground truth masks.\n",
    "        \n",
    "    Returns:\n",
    "        (float) the mean value of the metric\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    inferer = monai.inferers.SlidingWindowInferer(roi_size=[256, 256])\n",
    "    discrete_transform = monai.transforms.AsDiscrete(threshold=0.5)\n",
    "    Sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    mean_value = 0\n",
    "    \n",
    "    for sample in dataloader:\n",
    "        with torch.no_grad():\n",
    "            output = discrete_transform(Sigmoid(inferer(sample['img'].to(device), network=model).cpu()))\n",
    "        mean_value += metric_fn(output, sample[\"mask\"])\n",
    "    \n",
    "    return (mean_value / len(dataloader)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c239d0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_49750/489699043.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tutorial3_segmentation/{run_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run_id' is not defined"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(f\"tutorial3_segmentation/{run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d18258d9",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# ‚å®Ô∏è code your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37967f5b",
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# ‚å®Ô∏è code your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab016863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "\n",
    "def make_dummy_sample(sample):\n",
    "    M = sample['mask'].squeeze()\n",
    "    labels = measure.label(M)\n",
    "    dummy_labels = np.zeros((labels.shape[0], labels.shape[1]))\n",
    "    for i in np.unique(labels):\n",
    "        if i > 0:\n",
    "            mask_locs = np.where(labels == i)\n",
    "            limits = [np.min(mask_locs[0]), np.max(mask_locs[0]), np.min(mask_locs[1]), np.max(mask_locs[1])]\n",
    "            dummy_labels[limits[0]:limits[1], limits[2]:limits[3]] = 1\n",
    "    return torch.tensor(dummy_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32100db5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_49750/2614710951.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvisualize_rib_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'original mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvisualize_rib_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmake_dummy_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dummy segmentation masks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# dataset[[1, 3, 4]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/notebook_collaboration/lib/python3.7/site-packages/monai/data/dataset.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# if existing in cache, try to get the index in cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0mcache_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hash_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_num\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# support negative index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m             \u001b[0mcache_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "sample = test_set[0]\n",
    "visualize_rib_sample(sample, title = 'original mask')\n",
    "visualize_rib_sample({'img': sample['img'], 'mask': make_dummy_sample(sample)}, title = 'dummy segmentation masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd45945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric_dummy(dataloader, metric_fn):\n",
    "    \"\"\"\n",
    "    This function computes the average value of a metric for a data set using the dummy segmentation masks\n",
    "    \n",
    "    Args:\n",
    "        dataloader (monai.data.DataLoader): dataloader wrapping the dataset to evaluate.\n",
    "        metric_fn (function): function computing the metric value from two tensors:\n",
    "            - a batch of outputs,\n",
    "            - the corresponding batch of ground truth masks.\n",
    "        \n",
    "    Returns:\n",
    "        (float) the mean value of the metric\n",
    "    \"\"\"\n",
    "    \n",
    "    mean_value = 0\n",
    "    A = monai.transforms.AddChannel()\n",
    "    \n",
    "    for sample in dataloader:\n",
    "        output = make_dummy_sample(sample)\n",
    "        mean_value += metric_fn(A(A(output)), sample[\"mask\"])\n",
    "    \n",
    "    return (mean_value / len(dataloader)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3aa88089",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_49750/2878529152.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Mean Dice: {compute_metric_dummy(test_loader, monai.metrics.compute_meandice):.3f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/07/x0gf6dj176dfjvrn357t5p6h0000gn/T/ipykernel_49750/797961195.py\u001b[0m in \u001b[0;36mcompute_metric_dummy\u001b[0;34m(dataloader, metric_fn)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmean_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean_value\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "print(f'Mean Dice: {compute_metric_dummy(test_loader, monai.metrics.compute_meandice):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11306a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚å®Ô∏è code your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}